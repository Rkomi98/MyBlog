# robots.txt
# Rispetta il traffico umano e vieta un crawling aggressivo/automatizzato.

User-agent: GPTBot
Disallow: /

User-agent: ChatGPT-User
Disallow: /

User-agent: Google-Extended
Disallow: /

User-agent: CCBot
Disallow: /

User-agent: Omgilibot
Disallow: /

User-agent: Amazonbot
Disallow: /

User-agent: Bytespider
Disallow: /

User-agent: *
Disallow:
Crawl-delay: 10

Sitemap: https://rkomi98.github.io/MyBlog/sitemap.xml
