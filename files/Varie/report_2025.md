# Report AI 2025: cosa Ã¨ cambiato davvero

## Abstract

Nel 2025 la GenAI ha smesso di essere solo ChatGPT e usato solo risponde a delle domande "sempliciâ€, ma ha permesso di fare tante altre cose: dalle ricerche su centinaia di fonti browser "agentici", IDE che lavorano a fianco degli sviluppatori, e lâ€™open/local si fa davvero competitivo. Questo articolo ricostruisce mese per mese i rilasci chiave, confronta i principali player e chiude con le lezioni pratiche e i trend piÃ¹ probabili per il 2026.

Questo report racconta il 2025 **in modo molto pratico** dal punto di vista di uno che fino a un anno fa era studente, e ora si occupa di portare la GenAI e le sue applicazioni nelle azinede: cosa Ã¨ uscito, cosa ha davvero cambiato le abitudini, e quali aziende hanno â€œportato a casaâ€ risultati concreti. 

---

## Timeline 2025 (completa e spiegata)

Una miniâ€‘legenda che per alcuni sarÃ  banale, ma non per altri no, penso sia necessaria. Di conseguenza ecco a te:
- **Modelli â€œPro / topâ€**: li chiami quando devi risolvere task molto complesse (ragionamenti lunghi, decisioni difficili, codice delicato).
- **Modelli â€œFlash / fastâ€**: li chiami quando devi *assolvere compiti semplici* (riassunti, classificazioni con degli esempi, triage, customer care, piccole automazioni ripetute).
- **Modelli â€œopen / localiâ€**: li scegli quando contano **controllo, costi, privacy**, e vuoi farli girare su server dedicati o addirittura sul tuo computer.
- **Agenti (ricerca, IDE, browser con pilota, creatori di app)**: l'AI agentica ha cambiato davvero le abitudini delle persone: quindi parlando con il chatbot, questo delega agli strumenti piÃ¹ adatti in base alle esigenze. Questo apre una marea di possibili scenari e applicazioni nella vita di tutti i giorni.

---

### Gennaio 2025
Gennaio ha dimostrato che non servono grandissimi budget per creare dei buoni modelli:

- **Codestral 25.01 (Mistral, coding)**
  - Quando: **13 gennaio 2025**
  - In breve: modello di Mistral specializzato in **generazione e completamento di codice**, pensato per IDE, refactor e assistenza allo sviluppo.
  - Fonte: **[F05]**

- **DeepSeekâ€‘R1 (reasoning, open)**
  - Quando: **20 gennaio 2025**
  - In cosa consiste: modello open orientato al **ragionamento strutturato** (passi logici, catene di pensiero) e a task complessi, con focus su accessibilitÃ  e costi.
  - PerchÃ© Ã¨ importante? il ragionamento non Ã¨ piÃ¹ un'esclusiva di OpenAI diventa accessibile anche a team che non possono spendere come i big.
  - Fonte: **[F03]**

- **Stargate Project (OpenAI + SoftBank + Oracle + MGX, infrastruttura)**
  - Quando: **21 gennaio 2025**
  - In breve: maxiâ€‘progetto di infrastruttura AI con partnership e investimenti congiunti per **costruire/garantire capacitÃ  di calcolo** (data center, energia, cloud) e renderla disponibile per l'addestramento e l'uso su larga scala dei modelli.
  - PerchÃ© conta: sposta l'attenzione su **supply chain del compute** (data center, energia, raffreddamento, chip) e su accordi industriali di lungo periodo. In pratica, il vantaggio competitivo si gioca anche su chi riesce a garantire **capacitÃ  stabile e scalabile** per mesi/anni, non solo su chi addestra il modello piÃ¹ forte.
  - Fonte: **[F01]** (supporto: [F02])


- **Operator (OpenAI)**:
  -Quando: **23 gennaio**
  In cosa consiste: un assistente che non si limita a rispondere, ma usa un browser (clic, scroll, moduli) per fare azioni al posto tuo. Ãˆ lâ€™inizio del â€œpilota automaticoâ€ sul web, poi confluito nella modalitÃ  agent di ChatGPT a luglio.

- **Humanityâ€™s Last Exam (benchmark, â€œdomande cattiveâ€)**
  - Quando: **24 gennaio 2025** (pubblicazione paper)
  - In cosa consiste: benchmark di valutazione con **domande molto difficili** per misurare ragionamento, robustezza e generalizzazione.
  - In breve: sposta lâ€™asticella da â€œquanto scrive beneâ€ a â€œarriva davvero a risolvere task complesseâ€.
  - Fonte: **[F04]**

---

### Febbraio 2025
A febbraio Ã¨ nato lo strumento che piÃ¹ ha rivoluzionato la mia vita: Deep Research.

Deep Research ha accelerato e migliorato la qualitÃ  della ricerca. Studiare oggi Ã¨ un piacere per chi, come me Ã¨ super curioso e vuole avere sempre sotto controllo piÃ¹ fonti contemporaneamente.

- **Deep Research (OpenAI, ricerca guidata fino al report)**
  - Quando: **3 febbraio 2025**
  - In cosa consiste: workflow/feature per **ricerca assistita** che produce report strutturati con fonti e citazioni.
  - In breve: nasce lâ€™abitudine â€œVoglio saperne di piÃ¹ su un argomentoâ€: questo fa partire una pipeline composta da piano â†’ raccolta fonti â†’ sintesi con citazioni â†’ conclusioni.
  - Fonte: **[F06]**

- **Le Chat (Mistral, prodotto consumer/enterprise)**
  - Quando: **6 febbraio 2025** (annuncio/launch pubblico riportato dalla stampa)
  - In cosa consiste: prodotto chat di Mistral con **app e interfaccia** pensate per uso consumer e aziendale.Mistral prova a competere sul terreno dellâ€™esperienza dâ€™uso (velocitÃ , bassa latenza) con un posizionamento tutto europeo.
  - Fonte: **[F07]**

- **GPTâ€‘4.5 (OpenAI, piÃ¹ tenuta e affidabilitÃ )**
  - Quando: **27 febbraio 2025**
  - In cosa consiste: aggiornamento del modello di punta OpenAI con **migliore affidabilitÃ ** su task lunghi. Nasce uno dei modelli piÃ¹Ã¹ economici e piÃ¹ usati per la scrittura.
  - Fonte: **[F08]**

- **â€œVibe codingâ€ entra nel vocabolario**
  - Quando: **2 febbraio 2025** (il termine esplode dopo un post/tweet di Andrej Karpathy)
  - In cosa consiste: modo di sviluppare in cui **l'AI scrive gran parte del codice** e l'umano guida iterazioni, test e qualitÃ .
  - In breve: molte persone iniziano a lavorare cosÃ¬: *non scrivo ogni riga, ma guido  un sistema AI e ad ogni iterazione chiedo di cambiare alcune cose fino a quando lâ€™app non sta in piedi*.
  - Fonte: **[F09]**

---

### Marzo 2025 â€” Google chiarisce la strategia: potenza, velocitÃ , controllo

- **Gemini 2.5 Pro (Google, preview)**
  - Quando: **25 marzo 2025**
  - In cosa consiste: modello Google di fascia alta (preview) per **ragionamento profondo** e task complessi.
  - In breve: â€œscelta profondaâ€ per ragionamenti lunghi, analisi tecniche, codice complesso.
  - Fonte: **[F10]**

- **Gemma 3 (Google, open)**
  - Quando: **10 marzo 2025**
  - In cosa consiste: famiglia di modelli **open** di Google, pensati per deployment locali e custom.
  - In breve: lâ€™open non Ã¨ piÃ¹ un hobby: diventa unâ€™opzione reale per fare assistenti interni e automazioni vicino ai dati.
  - Fonte: **[F11]**

---

### Aprile 2025 â€” Il multimodale matura e lâ€™open alza la posta

- **Llama 4 (Meta, open: Scout/Maverick)**
  - Quando: **5 aprile 2025**
  - In cosa consiste: nuova generazione di modelli open di Meta (Scout/Maverick) con **contesti lunghi** e uso locale.
  - In breve: spinge forte su contesti lunghi e su modelli â€œda tenere in casaâ€, utili per documenti e codice.
  - Fonte: **[F13]**

- **Pixtral Large 25.02 (Mistral, visione + testo)**
  - Quando: **8 aprile 2025** (rilascio su AWS Marketplace)
  - In cosa consiste: modello Mistral **multimodale** (testo + immagini) per analisi visive e documenti. Questo Ã¨ un altro segnale della linea europea: multimodale, ma pensato per casi dâ€™uso pratici.
  - Fonte: **[F14]**

- **o3 e o4â€‘mini (OpenAI, ragionamento â€œpronto al lavoroâ€)**
  - Quando: **16 aprile 2025**
  - In cosa consiste: coppia di modelli OpenAI orientati al **ragionamento operativo**, con varianti di potenza/costo. Questi modelli vengono usati soprattutto per debugging, code review, e analisi documenti.
  - Fonte: **[F12]**

- **Qwen3 (Alibaba, hybrid reasoning)**
  - Quando: **29 aprile 2025**
  - In cosa consiste: nuova famiglia di modelli Alibaba con **ragionamento ibrido** e distribuzione cloud locale.
  - In breve: rafforza un ecosistema Asiaâ€‘first molto competitivo, soprattutto nel cloud locale.
  - Fonte: **[F15]**

- **Lovable 2.0 (creatore di app, noâ€‘code/lowâ€‘code)**
  - Quando: **24 aprile 2025**
  - In cosa consiste: piattaforma per **creare app senza codice**, con assistenza AI e workflow guidati.
  - In breve: rende â€œnormaleâ€ costruire prototipi e microâ€‘tool interni senza essere sviluppatori esperti.
  - Fonte: **[F29]**

---

### Maggio 2025 â€” Lâ€™AI entra nei prodotti di massa

- **AI Mode in Google Search (ricerca in stile â€œassistenteâ€)**
  - Quando: **20 maggio 2025**
  - In cosa consiste: nuova esperienza Search con **risposte sintetiche e conversazionali** al posto della lista di link.
  - In breve: per molti la ricerca smette di essere una lista di risultati e diventa un dialogo con sintesi.
  - Fonte: **[F16]**

- **Veo 3 (Google/DeepMind, video con audio)**
  - Quando: **20 maggio 2025** (copertura stampa di lancio)
  - In cosa consiste: modello generativo per **video con audio sincronizzato**, pensato per produzione rapida.
  - In breve: impatto enorme su training, marketing, demo interne e didattica.
  - Fonte: **[F17]**

- **Claude 4 (Anthropic: Opus/Sonnet)**
  - Quando: **22 maggio 2025**
  - In cosa consiste: nuova famiglia di modelli Anthropic (Opus/Sonnet) con **focus su ragionamento e coding**.
  - In breve: cresce lâ€™idea del â€œcollega digitaleâ€ che regge lavori lunghi, soprattutto sul coding.
  - Fonte: **[F18]**

- **Perplexity Labs (modalitÃ  â€œa progettoâ€)**
  - Quando: **29 maggio 2025**
  - In cosa consiste: modalitÃ  che trasforma le richieste in **progetti con output** (report, piani, file). Diventa semplice fare dashboard interattive a partire dai dati presenti sul web.
  - In breve: rende piÃ¹ semplice il passaggio da â€œchiedere coseâ€ a â€œcommissionare risultatiâ€ (report, piani, file).
  - Fonte: **[F19]**

- **Gemma 3n (Google, onâ€‘device)**
  - Quando: **20 maggio 2025**
  - In cosa consiste: versione **leggera onâ€‘device** dei modelli Gemma per girare su hardware locale.
  - In breve: porta lâ€™idea di sistemi AI on device.
  - Fonte: **[F20]**

---

### Giugno 2025 â€” Lâ€™Europa mette una bandierina sul ragionamento

- **Magistral (Mistral, reasoning)**
  - Quando: **10 giugno 2025**
  - In cosa consiste: modello Mistral orientato al **ragionamento per passaggi**, con target enterprise.
  - In breve: Mistral entra nel campo dei modelli che ragionano per passaggi, con un tono molto â€œda prodottoâ€ e attento al contesto europeo.
  - Fonte: **[F21]**

---

### Luglio 2025 â€” Il browser con pilota si fa concreto

- **Comet (Perplexity, browser con pilota: beta pubblica a scaglioni)**
  - Quando: **9 luglio 2025**
  - In cosa consiste: browser con **agente integrato** per ricerca e azioni sul web, in beta progressiva.
  - In breve: â€œlâ€™ufficio nel browserâ€ diventa una cosa reale: ricerca, azioni sul web, piccoli flussi.
  - Fonte: **[F22]**

- **ChatGPT agent / â€œagent modeâ€**
  - Quando: 17 luglio:
  - In cosa consiste: dentro ChatGPT compare una modalitÃ  che unisce ricerca e azione. Non fa solo sintesi: naviga e usa un computer â€œvirtualeâ€, esegue passi in sequenza e puÃ² arrivare a un risultato editabile (es. slide, fogli, report).

---

### Agosto 2025 â€” Il salto di generazione

- **GPTâ€‘5 (OpenAI)**
  - Quando: **7 agosto 2025**
  - In cosa consiste: nuova generazione del modello OpenAI, pensata per **capabilities e contesti piÃ¹ ampi**.
  - In breve: aumenta la sensazione di continuitÃ  su lavori lunghi: non solo risposte, ma accompagnamento fino alla consegna.
  - Fonte: **[F23]**

---

### Settembre 2025 â€” Efficienza: fare scala senza bruciare budget

- **Gemini 2.5 Flashâ€‘Lite (Google, preview)**
  - Quando: **settembre 2025** (indicato come â€œ09â€‘2025â€ nei materiali di rilascio)
  - In cosa consiste: variante **veloce ed economica** di Gemini per automazioni ad alto volume.
  - In breve: benzina per automazioni ripetute (riassunti, classificazioni, triage) a costo piÃ¹ basso.
  - Fonte: **[F24]**

---

### Ottobre 2025 â€” Il web diventa â€œoperativoâ€

- **ChatGPT Atlas (OpenAI, browser con pilota)**
  - Quando: **21 ottobre 2025**
  - In cosa consiste: esperienza ChatGPT con **navigazione e azioni sul web** gestite dall'agente.
  - In breve: lâ€™assistente non si limita a spiegare: puÃ² navigare, compilare, seguire passaggi, raccogliere dati.
  - Fonte: **[F25]**

- **Cursor (Anysphere) e la stagione del coding â€œin compagniaâ€**
  - Quando: **Q4 2025 (rilasci e rollout a scaglioni)**
  - In cosa consiste: editor/IDE con **assistente AI integrato** per scrittura, refactor e review in tempo reale.
  - In breve: lâ€™editor smette di essere un posto dove â€œscriviâ€ e diventa un posto dove **coordini** (scrivi, controlli, refactorizzi, testi).
  - Nota: qui la data precisa dipende da canali/rollout; in questa versione ho preferito non fissare un giorno unico senza una fonte primaria univoca.

---

### Novembre 2025 â€” Google rilancia sul â€œProâ€

- **GPTâ€‘5.1 (OpenAI)**
  - Quando:12 novembre
  - In cosa consiste: aggiornamento della serie GPTâ€‘5 con due modalitÃ  (piÃ¹ â€œistantaneaâ€ e piÃ¹ â€œragionataâ€) e piÃ¹ controllo sul tono. In pratica: conversazioni piÃ¹ naturali, e meno attrito quando devi passare dallâ€™idea al lavoro finito. Ho notato che lo switch automatico funzionava meglio e il grounding piÃ¹ affidabile

- **Gemini 3 Pro (Google)**
  - Quando: **18 novembre 2025**
  - In cosa consiste: modello Google di fascia alta per **task complessi multimodali** e contesti lunghi.
  - In breve: torna forte sul lavoro complesso (testo + immagini + contesti lunghi), con focus su scenari reali.
  - Fonte: **[F26]**

---

### Dicembre 2025 â€” Consolidamento e â€œcostruttori di softwareâ€

- **GPTâ€‘5.2 (OpenAI)**
  - Quando: **11 dicembre 2025**
  - In cosa consiste: aggiornamento incrementale del modello con **migliorie di stabilitÃ ** e ragionamento. Funziona meglio con le immagini, su chat lunghe e complesse. Migliora anche nel coding.
  - In breve: spinge su lavoro professionale e progetti multiâ€‘passo (piÃ¹ stabilitÃ  operativa).
  - Fonte: **[F27]**

- **Gemini 3 Flash (Google)**
  - Quando: **17 dicembre 2025**
  - In cosa consiste: versione **piÃ¹ veloce** di Gemini 3 per task rapidi e throughput elevato.
  - In breve: â€œveloce ma intelligenteâ€ come impostazione predefinita; riduce ancora i tempi morti.
  - Fonte: **[F28]**

---

## Focus: AI nello spazio (2025)

Nel 2025 la parola chiave nello spazio non Ã¨ â€œfantascienzaâ€, Ã¨ **autonomia**. Il motivo Ã¨ semplice: quando sei in orbita (o oltre), comunicare costa e arriva in ritardo. Quindi: piÃ¹ software capace di decidere e adattarsi a bordo, piÃ¹ missione efficiente.

### USA â€” piÃ¹ autonomia operativa e piÃ¹ disciplina sui dati

- **U.S. Space Force: piano Data & AI FY2025**
  - Quando: **19 marzo 2025**
  - Cosa segnala: lâ€™AI non Ã¨ solo â€œmodelloâ€, Ã¨ **organizzazione**: dati condivisi, alfabetizzazione, strumenti, governance.
  - Fonte: **[F31]**

- **Satelliti che decidono â€œse ha senso scattareâ€**
  - Quando: **25 luglio 2025** (racconto di una demo/test pubblico)
  - Cosa segnala: parte dellâ€™intelligenza si sposta a bordo: meno â€œscarico tutto a terraâ€, piÃ¹ â€œscelgo e filtro primaâ€.
  - Fonte: **[F32]**

*(Nota: molte attivitÃ  NASA/DoD sono continue e non sempre hanno una singola data â€œdi lancioâ€. In questa sezione ho incluso solo i punti dove una data pubblica Ã¨ esplicita.)*

### Cina â€” computing in orbita e costellazioni che elaborano dati a bordo

- **Avvio di una â€œspace computing constellationâ€ (iniziativa guidata da Zhejiang Lab)**
  - Quando: **15 maggio 2025**
  - Cosa segnala: spinta verso rete di satelliti che **processano dati direttamente in orbita**, riducendo trasferimenti a terra.
  - Fonte: **[F33]**

### Europa â€” affidabilitÃ , interoperabilitÃ , Earth Observation â€œserioâ€

Nel 2025 lâ€™Europa tende a muoversi con un approccio piÃ¹ â€œingegneristicoâ€: meno show, piÃ¹ verificabilitÃ .

- **ESA Î¦â€‘lab / AI4EO (AI for Earth Observation)**
  - Quando: **iniziativa continuativa (attiva nel 2025)**
  - Cosa segnala: focus su AI applicata a osservazione della Terra (clima, ghiacci, agricoltura, rischi).
  - Fonte: **[F34]**

---

## Una nota importante: chi ha investito tanto ma ha raccolto poco

Nel 2025 si Ã¨ visto un pattern ricorrente (vale in tutti i settori):
1) **Pilot eterno**: PoC belli, ma nessuno li porta in produzione. I PoC devono essere in primis fattibili e utili a chi poi li userÃ . Ultimo ma non meno importante deve essere chiaro il come utilizzarli. L'adoption diventa chiave in tal senso.
2) **Dati disordinati**: un problema vecchio come il cucco. I dati non possono essere duplicati, o confusi, e i processi devono essere standardizzati per essere adatti a trasformarli con l'AI.
3) **QualitÃ  non misurata**: senza metriche (errori, tempi, risparmi, rischi) lâ€™adozione resta emotiva e poi si spegne. Resta fondamentale un monitoraggio nel tempo per capire l'impatto e non tutti lo stanno facendo
4) **Governance vaga**: chi puÃ² usare cosa? con quali dati? chi firma lâ€™output? se nessuno decide, nessuno scala.

La differenza tra chi ha vinto e chi ha perso nel 2025 Ã¨ stata quasi sempre qui: **processi + dati + responsabilitÃ **, piÃ¹ che â€œil modello piÃ¹ nuovoâ€.

---

## Azienda per azienda: cosa hanno fatto bene, cosa no, e voto finale

> **Come leggo il voto (0â€“10):** utilitÃ  concreta, qualitÃ , velocitÃ  di miglioramento, distribuzione, chiarezza di prodotto.

### OpenAI â€” 9+

**La storia dellâ€™anno:** prima della classe, ma ha toppato lâ€™esame che guardavano tutti: GPTâ€‘5.

**Cosa ha fatto bene**

Le due perle dellâ€™anno: Deep Research e Agent/Operator. Una ti fa il report (con fonti), lâ€™altra si mette lÃ¬ e fa le cose (clic, form, ricerche, raccolta info). Queste due, per me, sono state davvero â€œwowâ€ perchÃ© ti fanno risparmiare ore.
Sul coding: Codex Ã¨ quello che le ha rimesso benzina. Quando devi lavorare sul repo vero e non su 10 righe buttate in chat, lÃ¬ OpenAI ha recuperato terreno.
La toppata: GPTâ€‘5. Annuncio lungo, un poâ€™ fuffoso, e la sensazione generale che â€œokâ€¦ e quindi?â€. Poi si Ã¨ ripresa alla fine con il colpo di reni.
Nota personale: i modelli di ragionamento sono stati un'altra figata, ma sono una notizia dell'anno scorso. 

**Dove ha toppato (secondo la mia percezione)**

* **GPTâ€‘5** Ã¨ stato lâ€™esame in cui tutti guardavano: aspettative enormi, annuncio lungo, e la sensazione per molti di â€œtanto rumore e poca sostanzaâ€. Bello abbassare le allucinazioni ma i fatti hanno detto altro.

**PerchÃ© un 9+**

* PerchÃ©, nonostante lo scivolone, a fine anno ha rimesso la testa davanti con sprint finale. In generale quando ti serve chiudere roba, spesso Ã¨ ancora la scelta piÃ¹ completa.

---

### Google / DeepMind â€” **9.5/10**

**La storia dellâ€™anno:** recupera tantissimo terreno e, a inizio dicembre, dÃ  davvero lâ€™impressione di superare OpenAI. Poi OpenAI scatta in avanti in zona Cesarini, ma â€œla distanzaâ€ ormai Ã¨ minima.

**Cosa ha fatto benissimo**

* Ha vinto con lâ€™**ecosistema**: se consideri Search, Workspace, Android, YouTube e la distribuzione, quando Google muove un bottone lo senti dappertutto.
* **NotebookLM** Ã¨ stato il colpo piÃ¹ sottovalutato e piÃ¹ potente: ha reso lo studio e lâ€™onboarding piÃ¹ leggeri (audio, riassunti guidati, infografiche slides ecc).
* La strategia â€œfamiglia di strumentiâ€ Ã¨ chiara: quando serve profonditÃ  vai di **Pro**, per la vita quotidiana vai di **Flash**, e se vuoi controllo e localâ€‘first guardi a **Gemma**.

**Odi et amo (e qui ti capisco)**

* **AI Mode**: comodissimo, ma non sempre affidabile; quando sbaglia, allucina di brutto. #Capiamo
* Alcune cose tolte o limitate (tipo il **controllo schermo** in AI Studio) fanno storcere il naso: erano quelle feature che ti facevano dire â€œok, qui ci siamoâ€.

**PerchÃ© 9.5 e non 10**

* Troppi tool come Opal che sono ancora da integrare. Troppe cose che fanno la stessa cosa e entrano in competizione tra di loro.

---

### Anthropic â€” **9.0/10**

**La storia dellâ€™anno:** il *modello del coding*.

Non fa mille cose, ma quelle che fa le fa bene. E soprattutto: se gli chiedi una cosa, spesso ti risponde con codice che ti produce il risultato.
- Vuoi presentazioni? Scrive codice per farle.
- Vuoi documenti? Scrive codice per farli.
- Vuoi tabelle Excel? Ti tira fuori il codice e ti crea il file.
- Hai incollato un papiro infinito? Lui prova comunque a â€œimpacchettarloâ€ in qualcosa di sensato.

**Cosa ha fatto bene**

Consistenza su compiti lunghi e su contesti complessi. Carina la loro Deep research


**Il difetto grosso**

* Ãˆ **molto cara**. E quando la usi tanto, il costo lo senti.

---

### Meta â€” **5.0/10**

**La storia dellâ€™anno**: pensavo di darle meno, ma almeno ci ha provato.
- I modelli sono usciti e, per come li ho vissuti io, hanno floppato.
- La scelta di obbligarti a vedere il loro modello sul telefono ogni giorno... Non lo capisco. O meglio capisco la logica, ma Ã¨ una mossa strana.
- Via API: tra i peggiori che ho provato (insieme a IBM Granite).

**Cosa ha fatto bene**

* Il valore vero resta lâ€™open: il fatto che tanti pezzi siano **rilasciati open** permette al mondo di testarli, adattarli, farci ricerca e costruirci attorno.

**Cosa non ha funzionato (secondo la mia esperienza)**

* Prestazioni: via API Ã¨ stato uno dei modelli peggiori che ho provato (insieme a IBM Granite).
* Distribuzione â€œforzataâ€: la scelta di spingere il modello dentro le principali app di Meta in modo molto obbligatorio Ã¨â€¦ Diciamo particolare. Capisco la logica, ma lâ€™effetto â€œimposizioneâ€ puÃ² diventare un boomerang.

**PerchÃ© non scendo sotto 5:** perchÃ© rilasciare open, anche quando non brilli, Ã¨ comunque un atto utile per lâ€™ecosistema.

### Mistral â€” **8.0/10**

**La storia dellâ€™anno:** finalmente unâ€™alternativa europea che piano piano arriva quasi al livello degli altri.

**Cosa ha fatto bene**

* Ãˆ arrivata la **memoria** (e lâ€™idea Ã¨ buona: utile senza diventare invadente).
* Sono arrivati i modelli speech con **Voxtral**.
* Lâ€™italiano, stando ai benchmark, va **meglio del francese**. 
* **Mistral Small** Ã¨ stato il mio modello open preferito dellâ€™anno: pratico, veloce, â€œda lavoroâ€.

**Dove puÃ² crescere ancora**

* Nei flussi di ricerca â€œlunghiâ€ (deep research) câ€™Ã¨ spazio per fare di piÃ¹.
* Sui documenti (lettura/estrazione/riassunto su file complessi) manca ancora qualcosina per essere davvero una scelta â€œdefaultâ€.
* Ãˆ ancora poco conosciuta fuori dai cerchi tecnici.

**PerchÃ© il voto Ã¨ 8:** ottima direzione e identitÃ  forte; non Ã¨ ancora â€œovunqueâ€, ma sta diventando credibile.

### Microsoft â€” **6.5/10**

**La storia dellâ€™anno:** FINALMENTE.

Finalmente ha deciso di non mettere lâ€™esclusiva su OpenAI. Finalmente ha prestazioni decenti. Finalmente ha un sacco di feature carine prese (e adattate) da ciÃ² che ha funzionato altrove.

**Cosa ha fatto bene**

* Ha iniziato a muoversi in modo piÃ¹ indipendente e pragmatico.
* Ha una distribuzione enorme: se azzecca lâ€™esperienza, puÃ² diventare la porta dâ€™ingresso per tantissimi.

**Cosa non mi convince ancora**

* AffidabilitÃ  operativa: un down del servizio **martedÃ¬ 9 dicembre** ha creato parecchi problemi.
* Tantissimo potenziale, ma non si applica ancora abbastanza, specialmente nel suo software proprietario (dove potrebbe spingere davvero sulla produttivitÃ ).

**PerchÃ© il voto Ã¨ 6.5:** sei mesi fa non pensavo di dargli la sufficienza. Ora ci siamo, ma manca poco per trasformare il potenziale in una â€œmacchina da lavoroâ€ davvero stabile.

### Perplexity â€” **8.0/10**

**La storia dellâ€™anno:** Comet Ã¨ figo, ma Labs lo Ã¨ di piÃ¹.

**Cosa mi piace**

* La modalitÃ  â€œa progettoâ€ Ã¨ pratica: parti con una domanda e finisci con un risultato giÃ  usabile.
* La rassegna stampa usando compiti + Labs rende davvero piÃ¹ semplice restare aggiornati.
* Il modo in cui â€œprendeâ€ le informazioni, per me, Ã¨ spesso piÃ¹ affidabile di altri competitor (parere personale).

**Cose che mi lasciano perplesso**

* Le **deep research** sono troppo brevi: quando stai lavorando su cose serie, vorresti piÃ¹ profonditÃ .
* Prezzo: non Ã¨ economico, ma il Pro Ã¨ incluso in bundle (tipo TIM/PayPal).

---

### xAI â€” **6.9/10**

**La storia dellâ€™anno:** velocissimo, ma pieno di spigoli.

Non so, sarÃ  per lâ€™approccio â€œsenza filtriâ€ e a immagine e somiglianza del suo "papÃ ": io faccio fatica a considerarlo un prodotto davvero commerciabile, perchÃ© spesso **tocca confini etici** che in azienda non puoi ignorare.

**PerÃ²â€¦**

* Ãˆ tra i piÃ¹ rapidi per certe cose (coding â€œal voloâ€, creativitÃ , immagini).
* A volte la libertÃ  di tono lo rende sorprendentemente utile, finchÃ© non diventa un rischio.

**PerchÃ© 6.9:** utilissimo per alcune cose, ma troppo â€œnon governabileâ€ per diventare un default professionale.

---

### Alibaba â€” **8.0/10**

**La storia dellâ€™anno:** la famiglia Qwen spinge parecchio.

Ho poco da dire perchÃ©, in generale, i modelli si fanno rispettare e sono diventati un pezzo importante dellâ€™ecosistema.

**PerchÃ© non do di piÃ¹ (nota personale, traumatica ğŸ˜„)**
Una volta ho fatto un casino incredibile su un server europeo per colpa di Qwen: Ã¨ stato lâ€™unico che si era sbilanciato e mi aveva risposto su come forzare lâ€™aggiornamento di CUDA. Trauma a vita.

**PerchÃ© comunque resta un 8:** direzione solida, modelli competitivi, spinta reale. Soloâ€¦ ecco, io ormai li tratto con i guanti.

### DeepSeek â€” **7.8/10**

**La storia dellâ€™anno:** il pesciolone biondo che ha fatto impazzire il mondo.

A gennaio crea un terremoto: improvvisamente si capisce che OpenAI **non Ã¨ piÃ¹ irraggiungibile** e che la qualitÃ  â€œaltaâ€ puÃ² arrivare anche da un attore meno ovvio.

**Cosa ha fatto bene**

* Ha dimostrato che il ragionamento â€œserioâ€ puÃ² essere piÃ¹ accessibile e meno legato a budget enormi.
* Ha continuato a spingere sul fronte ricerca, e con **DeepSeekâ€‘V3.2** ha fatto capire di essere ancora vivo.

**Cosa non ha funzionato (secondo la mia esperienza)**

* Problemi etici/sicurezza: sono emersi dubbi e criticitÃ  che rendono difficile usarlo â€œa cuor leggeroâ€ in contesti professionali.
* Non Ã¨ rimasto sempre al passo dei competitor sul prodotto finito (integrazioni, esperienza consumer, continuitÃ  di rilascio).

**Cosa vorrei vedere nel 2026**

* Se lo sforzo Ã¨ serio, oltre alla ricerca investirei anche sul lato **consumer** (esperienza, affidabilitÃ , funzioni quotidiane).

**PerchÃ© il voto Ã¨ 7.8 e non piÃ¹ alto:** impatto enorme iniziale, ma serve piÃ¹ continuitÃ  e piÃ¹ prodotto.

### Cursor / Anysphere â€” **10/10**

**La storia dellâ€™anno:** progetto di sviluppo pazzesco.

Mi ha fatto ridere quando GPTâ€‘5 Ã¨ uscito prima lÃ¬ che su ChatGPT: Ã¨ un segnale di quanto sia diventato veloce nel portare novitÃ  *dove serve davvero*.

Ãˆ il mio IDE di riferimento: in un anno Ã¨ cresciuto tantissimo e ha reso naturale un modo di lavorare â€œa cicliâ€: propongo â†’ genero â†’ provo â†’ correggo â†’ rifaccio. Quando entra nel flow, ti fa macinare lavoro.

**PerchÃ© 10:** impatto quotidiano enorme e miglioramento continuo senza perdere la bussola.

---

### Lovable e â€œcreatori di appâ€ â€” **8.0/10**

**La storia dellâ€™anno:** il posto migliore (online) per fare vibe coding â€œda demo a cosa che giraâ€.

Per fare mock collegati a un piccolo DB (tipo Supabase) Ã¨ davvero figo: dallâ€™idea al prototipo in poche ore.

**PerchÃ© non Ã¨ piÃ¹ alto**

* Il tratto finale resta "duro": Ã¨ difficile fare manutenzione, gestire la sicurezza, e in generale gestire la qualitÃ  â€œda produzioneâ€.  
* Quando un progetto cresce, spesso serve comunque una mano piÃ¹ esperta per evitare di accumulare debito tecnico.

**PerchÃ© Ã¨ 8:** direzione giusta e impatto enorme su prototipi/MVP.

---

### Apple â€” **2.0/10**

**La storia dellâ€™anno:** ci ha provato due volte e, per molte persone, ha fallito due volte.

Lâ€™ultima volta che ho chiesto a unâ€™amica â€œcome funziona Apple Intelligence?â€, mi ha risposto: â€œCosâ€™Ã¨?â€. E questo, secondo me, dice tutto.

**PerchÃ© cosÃ¬ basso**

* Arriva tardi e a scaglioni, e molta gente non capisce cosa Ã¨ disponibile davvero e cosa no.

---

### Spazio e difesa (settore) â€” **7.4/10**

**La storia dellâ€™anno:** meno hype, piÃ¹ piani reali.

**Cosa va forte**

* Roadmap e sperimentazioni concrete su robotica e autonomia.

**Cosa frena**

* Cicli lunghi, sicurezza, certificazioni.

---

## Conclusione â€” Le scoperte del 2025 e cosa aspettarsi nel 2026

### Le 5 scoperte principali del 2025

1. **La ricerca Ã¨ diventata un lavoro completo**: non cerchi â€œunâ€™informazioneâ€, chiedi â€œun reportâ€.
2. **Lâ€™ufficio si sposta nel browser**: se il browser sa agire, tante attivitÃ  diventano piÃ¹ veloci.
3. **Il coding cambia ritmo**: piÃ¹ bozze, piÃ¹ test, piÃ¹ iterazioni rapide; meno tempo su compiti ripetitivi.
4. **Lâ€™hype non basta**: molte aziende scoprono che serve processo, dati puliti e misure di qualitÃ .
5. **Efficienza e responsabilitÃ  contano quanto la potenza**: costi, energia, controllo degli errori.

### Trend probabili per il 2026

* **Strumenti che lavorano a blocchi di 30â€“120 minuti**, non a colpi di singola risposta.
* **PiÃ¹ â€œpiloti automaticiâ€ dentro software esistenti** (browser, suite dâ€™ufficio, IDE).
* **Prezzi e metriche legati al risultato**, non solo al consumo.
* **PiÃ¹ attenzione a qualitÃ  e sicurezza** (specie in aziende e pubblica amministrazione).
* **PiÃ¹ esecuzione â€œin localeâ€** dove possibile, per costi e privacy.

---

### Appendice â€” Voti riassunti (per confronto rapido)

* Cursor/Anysphere 10.0
* Google/DeepMind 9.5
* OpenAI 9.2
* Anthropic 9.0
* Perplexity 8.0
* Lovable 8.0
* Alibaba 8.0
* Mistral 8.0
* DeepSeek 7.8
* Spazio/Difesa 7.4
* xAI 6.9
* Microsoft 6.5
* Meta 5.0
* Apple 2.0

## Appendice â€” Fonti (con link)

$1

* **[F02c]** OpenAI â€” [â€œIntroducing upgrades to Codexâ€](https://openai.com/index/introducing-upgrades-to-codex/) â€” 16 May 2025
* **[F02d]** OpenAI â€” [â€œgpt-5.1-codex-max (model docs)â€](https://platform.openai.com/docs/models/gpt-5-1-codex-max) â€” 2025
* **[F02a]** OpenAI â€” [â€œNew tools for building agentsâ€](https://openai.com/index/new-tools-for-building-agents/) â€” 11 Mar 2025
* **[F02b]** OpenAI â€” [â€œIntroducing ChatGPT agent: bridging research and actionâ€](https://openai.com/index/introducing-chatgpt-agent/) â€” 17 Jul 2025
* **[F03]** DeepSeek â€” [â€œDeepSeekâ€‘R1 Release Notesâ€](https://api-docs.deepseek.com/news/news250120) (weights: [Hugging Face](https://huggingface.co/deepseek-ai/DeepSeek-R1)) â€” 20 Jan 2025
* **[F04]** arXiv â€” [â€œHumanityâ€™s Last Examâ€](https://arxiv.org/abs/2501.14249) â€” 24 Jan 2025
* **[F05]** Mistral AI â€” [â€œCodestral 25.01â€](https://mistral.ai/it/news/codestral-2501) â€” 13 Jan 2025
* **[F06]** OpenAI â€” [â€œIntroducing deep researchâ€](https://openai.com/index/introducing-deep-research/) â€” 3 Feb 2025
* **[F07]** Mistral AI â€” [â€œThe all new le Chat: Your AI assistant for life and workâ€](https://mistral.ai/en/news/all-new-le-chat) â€” 6 Feb 2025
* **[F08]** OpenAI â€” [â€œIntroducing GPTâ€‘4.5â€](https://openai.com/index/introducing-gpt-4-5/) â€” 27 Feb 2025
* **[F09]** Ars Technica â€” [â€œWill the future of software development run on vibes?â€](https://arstechnica.com/ai/2025/03/is-vibe-coding-with-ai-gnarly-or-reckless-maybe-some-of-both/) â€” 5 Mar 2025
* **[F10]** Google â€” [â€œGemini 2.5: Our newest Gemini model with thinkingâ€](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/) â€” 25 Mar 2025
* **[F11]** Google â€” [â€œGemma 3: Googleâ€™s new open model based on Gemini 2.0â€](https://blog.google/technology/developers/gemma-3/) â€” 10 Mar 2025
* **[F12]** OpenAI â€” [â€œOpenAI o3 and o4â€‘mini System Cardâ€](https://openai.com/index/o3-o4-mini-system-card/) â€” 16 Apr 2025
* **[F13]** Meta â€” [â€œLlama 4â€](https://ai.meta.com/blog/llama-4/) (alt: [https://www.llama.com/llama4/](https://www.llama.com/llama4/)) â€” 5 Apr 2025
* **[F14]** AWS â€” [â€œAmazon Bedrock adds Mistral AI Pixtral Large 25.02â€](https://aws.amazon.com/about-aws/whats-new/2025/04/amazon-bedrock-mistral-ai-pixtral-large-25-02/) â€” 8 Apr 2025
* **[F15]** Qwen Team (Alibaba) â€” [â€œQwen3â€](https://qwenlm.github.io/blog/qwen3/) â€” 29 Apr 2025
* **[F16]** Google â€” [â€œAI Mode in Google Search: Updates from Google I/O 2025â€](https://blog.google/products/search/google-search-ai-mode-update/) â€” 20 May 2025
* **[F17]** Google DeepMind â€” [â€œVeoâ€](https://deepmind.google/models/veo/) â€” 20 May 2025
* **[F18]** Anthropic â€” [â€œIntroducing Claude 4â€](https://www.anthropic.com/news/claude-4) â€” 22 May 2025
* **[F19]** Perplexity â€” [â€œIntroducing Perplexity Labsâ€](https://www.perplexity.ai/hub/blog/introducing-perplexity-labs) â€” 29 May 2025
* **[F20]** Google â€” [â€œBuild transformative AI applications with Google AIâ€](https://blog.google/technology/developers/google-ai-developer-updates-io-2025/) â€” 20 May 2025
* **[F21]** Mistral AI â€” [â€œMagistralâ€](https://mistral.ai/en/news/magistral) â€” 10 Jun 2025
* **[F22]** Perplexity â€” [â€œIntroducing Cometâ€](https://www.perplexity.ai/hub/blog/introducing-comet) â€” 9 Jul 2025
* **[F23]** OpenAI â€” [â€œIntroducing GPTâ€‘5â€](https://openai.com/index/introducing-gpt-5/) â€” 7 Aug 2025
* **[F23a]** OpenAI â€” [â€œGPTâ€‘5.1: A smarter, more conversational ChatGPTâ€](https://openai.com/index/gpt-5-1/) â€” 12 Nov 2025
* **[F24]** Google â€” [â€œGemini 2.5 Flashâ€‘Liteâ€ (models docs)](https://ai.google.dev/gemini-api/docs/models/gemini#gemini-2.5-flash-lite) â€” Sep 2025
* **[F25]** OpenAI â€” [â€œIntroducing ChatGPT Atlasâ€](https://openai.com/index/introducing-chatgpt-atlas/) â€” 21 Oct 2025
* **[F26]** Google Workspace Updates â€” [â€œGemini 3 Proâ€](https://workspaceupdates.googleblog.com/2025/11/gemini-3-pro.html) â€” 18 Nov 2025
* **[F27]** OpenAI â€” [â€œIntroducing GPTâ€‘5.2â€](https://openai.com/index/introducing-gpt-5-2/) â€” 11 Dec 2025
* **[F28]** Google â€” [â€œGemini 3 Flashâ€](https://blog.google/products/gemini/gemini-3-flash/) â€” 17 Dec 2025
* **[F29]** Lovable â€” [â€œLovable 2.0â€](https://lovable.dev/blog/lovable-2-0) â€” 24 Apr 2025
* **[F30]** Lovable â€” [â€œSeries Bâ€](https://lovable.dev/blog/series-b) â€” 18 Dec 2025
* **[F31]** U.S. Space Force â€” [â€œData & AI FY2025 Strategic Action Planâ€](https://www.spaceforce.mil/Portals/1/Documents/Data%20and%20AI%20FY25%20Strategic%20Action%20Plan.pdf) â€” 19 Mar 2025
* **[F32]** NASA â€” [dynamic targeting / onboard decisionâ€‘making for Earth observation](https://www.nasa.gov/) â€” 25 Jul 2025
* **[F33]** Gov.cn â€” [news on â€œspaceâ€‘based computing constellationâ€](https://english.www.gov.cn/) â€” 15 May 2025
  $1
* **[F35]** PayPal â€” [â€œPayPal partners with Perplexity to help users shop smarterâ€](https://newsroom.paypal-corp.com/2025-06-25-PayPal-partners-with-Perplexity-to-help-users-shop-smarter) â€” 25 Jun 2025
* **[F36]** Reuters â€” [â€œPayPal partners with Perplexity to help users shop smarterâ€](https://www.reuters.com/world/us/paypal-partners-with-perplexity-help-users-shop-smarter-2025-06-25/) â€” 25 Jun 2025
* **[F37]** The Verge â€” [â€œApple drops â€˜available nowâ€™ from Apple Intelligence pageâ€](https://www.theverge.com/news/653413/apple-intelligence-available-now-advertising-claim) â€” 22 Apr 2025
* **[F38]** Ars Technica â€” [â€œAnthropic launches Claude Max plan for $200 per monthâ€](https://arstechnica.com/information-technology/2025/04/anthropic-launches-claude-max-plan-for-200-per-month/) â€” 9 Apr 2025
* **[F39]** Gartner Peer Insights â€” [â€œCursor reviews (AI code assistants)â€](https://www.gartner.com/reviews/market/ai-code-assistants/vendor/anysphere/product/cursor) â€” 2025
* **[F40]** Trustpilot â€” [â€œLovable reviewsâ€](https://www.trustpilot.com/review/lovable.dev) â€” 2025
