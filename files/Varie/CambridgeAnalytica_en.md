# From Cambridge Analytica to chatbots: how much is our privacy at risk?

## Abstract

The **Cambridge Analytica (CA)** scandal revealed how psychometric profiling can transform social media data into powerful tools for political micro-targeting. From 2014, [CA collected Facebook data ([1])](https://ico.org.uk/media2/migrated/2259371/investigation-into-data-analytics-for-political-purposes-update.pdf) from tens of millions of people through a quiz ("thisisyourdigitallife"), obtaining [**OCEAN profiles** ([2])](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=personality%20and%20other%20drivers%20that,second%20amendment%2C%20which%20guarantees%20the) (the "Big Five" personality traits) and matching them with demographic and consumer information. These **psychometric profiles** were used to segment the electorate and experiment with targeted political messages: for example, by modulating [pro-gun ads based on the "neuroticism" trait ([3])](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=%E2%80%98Openness%E2%80%99%2C%20%E2%80%98Conscientiousness%E2%80%99%2C%20%E2%80%98Extraversion%E2%80%99%2C%20%E2%80%98Agreeableness%E2%80%99%20and,39). CA propagated content on **Facebook** (via **Custom Audiences** and similar tools), testing ad variants with **A/B testing** techniques to maximize impact.

Okay, but what was the impact of all this?

Evidence on real effectiveness is mixed: [CA itself ([4])](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=micro,turnout%2C%20for%20the%20targeted%20groups) reported increases of **39%** in awareness on certain issues and a **+30%** in turnout for targeted groups in 2014 US campaigns.
However, other independent analyses [\[5\]](https://www.niemanlab.org/2018/03/this-is-how-cambridge-analyticas-facebook-targeting-model-really-worked-according-to-the-person-who-built-it/#:~:text=In%20an%20email%20to%20me%2C,like%20race%2C%20age%2C%20and%20gender)[\[6\]](https://www.niemanlab.org/2018/03/this-is-how-cambridge-analyticas-facebook-targeting-model-really-worked-according-to-the-person-who-built-it/#:~:text=Regarding%20one%20key%20public%20concern%2C,quite%20as%20it%20was%20billed) noted that CA's predictive model **did not significantly outperform normal demographic criteria**.

Today, similar logics of **intensive user data collection and use** are found in major **chatbot and LLM** (large language model) services. Consumer platforms like **ChatGPT** (OpenAI, [\[7\]](https://help.openai.com/en/articles/5722486-how-your-data-is-used-to-improve-model-performance#:~:text=improve%20over%20time,it%2C%20unless%20you%20opt%20out)) and **Gemini** (Google) by default **record user prompts, conversations, and feedback** and use them to continuously improve models [\[8\]](https://support.google.com/gemini/answer/13594961?hl=en). Private users can "opt-out" (i.e., refuse to share their data) by limiting the sharing of their conversation history, but in the absence of such a choice, chat data can be stored for extended periods (e.g., **OpenAI** keeps general user chats indefinitely to train models, unless opted out, while **Anthropic** from 2025 offers a choice: no training and 30-day retention or active training with **5-year** retention [\[9\]](https://www.anthropic.com/news/updates-to-our-consumer-terms#:~:text=Extended%20data%20retention)). In contrast, **business/enterprise** services offer **isolation** guarantees: for example, **OpenAI API/Enterprise** and **Microsoft 365 Copilot** ensure that input and output **do not feed into the training data** of public models [\[10\]](https://help.openai.com/en/articles/5722486-how-your-data-is-used-to-improve-model-performance#:~:text=Services%20for%20businesses%2C%20such%20as,Enterprise%2C%20and%20our%20API%20Platform)[\[11\]](https://learn.microsoft.com/en-us/copilot/microsoft-365/microsoft-365-copilot-privacy#:~:text=Important), remaining confined to the client's environment. On the **transparency and governance** front, companies have introduced **controls for users and administrators** (such as privacy dashboards, retention settings, objection forms for the EU [\[12\]](https://about.fb.com/news/2025/04/making-ai-work-harder-for-europeans/#:~:text=Beginning%20this%20week%2C%20people%20based,well%20as%20newly%20submitted%20ones)[\[13\]](https://about.fb.com/news/2025/04/making-ai-work-harder-for-europeans/#:~:text=As%20we%E2%80%99ve%20previously%20mentioned%2C%20we,being%20used%20for%20training%20purposes)) and adopted contractual commitments (e.g., **SOC 2**, **DPA** on data processing) to reassure businesses and regulators [OpenAI \[14\]](https://openai.com/enterprise-privacy/#:~:text=Comprehensive%20compliance)[Google \[15\]](https://support.google.com/a/answer/15706919?hl=en#:~:text=,outside%20your%20domain%20without%20permission). However, concerns remain: for example, the **DeepSeek** chatbot, a popular Chinese app, collects **every input, file, and chat history**, sending everything to servers in China [\[16\]](https://www.wired.com/story/deepseek-ai-china-privacy-data/#:~:text=To%20be%20clear%2C%20DeepSeek%20is,%E2%80%9D)[\[17\]](https://www.wired.com/story/deepseek-ai-china-privacy-data/#:~:text=The%20first%20of%20these%20areas,%E2%80%9D); this raises security doubts and has attracted the attention of experts for potential risks of government access [\[18\]](https://www.wired.com/story/deepseek-ai-china-privacy-data/#:~:text=DeepSeek%E2%80%99s%20privacy%20policy%20also%20says,is%20required%20to%20do%20so).

> To access this article, a Wired premium account is required.

In summary, from the Cambridge Analytica era to today's AI chatbot boom, users' **personal and behavioral data** have become the **"fuel for predictive and generative models"**. While this enables more "intelligent" services and tailored campaigns, it also poses new challenges for **privacy, control, and responsibility**. Platforms are responding with greater transparency (dedicated policies) and control options, but it is also up to users, and especially regulators, to demand **clarity on the use of their data**, exercise opt-out/off rights, and carefully evaluate what to share with these AIs.

## Cambridge Analytica: what happened?
Now let's look in detail at what happened with the Cambridge Analytica case. To do this, I will use the first two sources we saw in the article [1](https://ico.org.uk/media2/migrated/2259371/investigation-into-data-analytics-for-political-purposes-update.pdf),[2](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=personality%20and%20other%20drivers%20that,second%20amendment%2C%20which%20guarantees%20the)

### Data collected
Cambridge Analytica (an affiliate of **SCL Elections**) acquired a massive dataset of Facebook users in 2014-2015 through the company **GSR** (Global Science Research) of researcher Aleksandr Kogan. Kogan developed a personality quiz app ("thisisyourdigitallife") leveraging Facebook's Graph API, which at the time allowed extracting not only the data of the consenting user but also that of their **friends** (_friends permissions_ functionality valid until 2014). Approximately **320,000** Facebook users, mainly Americans, completed the OCEAN test by logging in via Facebook; in exchange for a few dollars, they gave the app permission to read a wide range of information: public profile (name, gender), date of birth, current city, **"Liked" pages**, wall posts, friend list, even private messages and tagged photos.

Since the app inherited the access rights of Kogan's previous academic app (developed before Facebook's 2015 restrictions), it could also collect data from participants' friends, if the latter had not set their privacy differently. **In total, ~87 million people** (including over **1 million** in the UK) underwent this massive data collection without their knowledge. Facebook confirmed the estimate and published the list of involved countries in 2018. Approximately **30 million** individuals had both Facebook data and psychometric quiz results matched, forming the core for predictive analyses.

### Psychometric characteristics (OCEAN model)

The Big Five personality model, known as **OCEAN** (Openness, Conscientiousness, Extroversion, Agreeableness, Neuroticism), was central to CA's profiling [\[2\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=personality%20and%20other%20drivers%20that,second%20amendment%2C%20which%20guarantees%20the). Kogan and colleagues applied methodologies from the Cambridge Psychometrics Centre (known for the "MyPersonality" project) which demonstrated how **Facebook Likes** could predict OCEAN traits and other personal attributes with surprising accuracy [\[19\]](https://ico.org.uk/media2/migrated/2259371/investigation-into-data-analytics-for-political-purposes-update.pdf#:~:text=OCEAN%20model%20and%20pioneer%20the,as%20ethnicity%20and%20political%20affiliation)[\[20\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=Cambridge%20Psychometrics%20Centre%2C%20Michal%20Kosinski%2C,to%20this%20approach%2C%20stating%20that).

In the contract stipulated with SCL on June 4, 2014, Kogan declared that his techniques allowed for predictivity "**close to test-retest**" in personality scores, with correlations such that an algorithm based on likes was _more accurate_ in describing a person than knowing their friends or even family members [\[21\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=Nix%20told%20us%3A%20%E2%80%9CWe%20do,41)[\[2\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=personality%20and%20other%20drivers%20that,second%20amendment%2C%20which%20guarantees%20the).

> This statement echoed a 2015 academic study [[22](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=Cambridge%20Psychometrics%20Centre%2C%20Michal%20Kosinski%2C,to%20this%20approach%2C%20stating%20that)], where Michal Kosinski, Kogan's colleague, showed that 70 Facebook likes outperformed friends in delineating an individual's psychological profile.

In practice, CA had estimated OCEAN scores for millions of US voters, obtained directly from the quiz or inferred through models trained on Kogan's data.

Since it might seem complicated now, let's take [an example](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=%E2%80%98Openness%E2%80%99%2C%20%E2%80%98Conscientiousness%E2%80%99%2C%20%E2%80%98Extraversion%E2%80%99%2C%20%E2%80%98Agreeableness%E2%80%99%20and,39). A user with a high "Neuroticism" score and low "Openness" was identified as **sensitive to messages of fear and order**, while a highly "Extraverted" individual might respond better to optimistic and social content. Cambridge Analytica **clustered** the public into psychographic groups and identified key themes for each segment: according to former CEO Alexander Nix, "presenting a fact supported by an emotion" was the strategy, adapting the argument to the audience's emotional profile [\[23\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=We%20are%20trying%20to%20make,109).

### Predictive models and ML employed

While not publishing technical details of its algorithms, CA combined **machine learning** approaches with traditional analytics. Kogan in [an email](https://www.niemanlab.org/2018/03/this-is-how-cambridge-analyticas-facebook-targeting-model-really-worked-according-to-the-person-who-built-it/) explained that his model for CA operated similarly to Netflix's recommendation system, i.e., via **SVD/factor analysis**: reducing a user-like matrix to latent components, which incorporated personality, demographics, and social networks together. In essence, the algorithm did not "openly" isolate the 5 traits but mixed them with dozens of other variables (age, gender, political orientation, etc.) into correlated factors useful for predicting electoral behavior.

As we did in the previous section, let's take an example. CA used _regressions_ and _decision trees_ to estimate the probability that an individual would support certain causes or candidates, given their known psychographic and demographic characteristics.

CA's data scientists built models to identify so-called **persuadables**, i.e., undecided voters strongly influenced by specific emotional levers. The volume of data (likes, tests, online and offline behaviors) also allowed the use of **shallow neural networks** or multivariate classification models to associate profiles with _outcomes_ of interest (vote, donation, abstention). **Facebook's look-alike models** played an important role: CA could upload lists of known users (e.g., individuals with high "openness" scores identified by the quiz) and use Facebook's algorithm to find other similar users, expanding the reach of targeting.

**Data→profile→targeting pipeline**

![Diagram of the Cambridge Analytica pipeline](../Assets/ca-data-pipeline.svg)

_Figure:_ the numbering follows the phases by which CA transforms social and commercial data into micro-targeted messages and continuously refines the models.

First, CA (via GSR) **extracts raw data** from social media (Facebook) and combines it with other sources (e.g., public **voter rolls**, data from commercial brokers such as purchases and subscriptions) [\[40\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=order%20to%20match%20the%20right,might%20support%20and%20how%20to). This data feeds into **psychometric analysis**: individual OCEAN traits are calculated from the quiz and likes, which are then **aggregated and inserted** into a unique profile for each voter (including age, gender, location, political leanings, etc.) [\[41\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=required%20under%20the%20contract%20to,electoral%20register%20in%20those%20states). On this basis, CA statisticians develop **predictive models** to segment the population into key groups (e.g., "insecure neurotics," "open progressives") and predict for each their susceptibility to specific messages [\[2\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=personality%20and%20other%20drivers%20that,second%20amendment%2C%20which%20guarantees%20the)[\[41\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=required%20under%20the%20contract%20to,electoral%20register%20in%20those%20states). In parallel, the creative team develops **message variants** (memes, videos, slogans) tailored to the psychological insights of the segments: for example, the same theme (such as gun rights) is packaged in a _fear and protection_ version for individuals with high neuroticism, and in a _sports hobby_ version for open/calm subjects [\[3\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=%E2%80%98Openness%E2%80%99%2C%20%E2%80%98Conscientiousness%E2%80%99%2C%20%E2%80%98Extraversion%E2%80%99%2C%20%E2%80%98Agreeableness%E2%80%99%20and,39). Messages are then **delivered via micro-targeting**: CA uploaded lists of target users (identified by name/ID, email, or phone) to Facebook and used tools like **Custom Audience** and **Dark Posts** to show different ads to different groups, without them being publicly visible to others [\[38\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=3%20The%20issue%20of%20data,GSR%20and%20Cambridge%20Analytica%20allegations)[\[39\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=data%2C%20involving%20various%20organisations%20including,overseas%20elections%20in%20Chapter%206). This phase included **A/B tests** and effectiveness checks: clicks, shares, view time, and conversion rates (e.g., event registration, donation) were monitored for each variant, then iterating on the winning creative. Finally, campaign results (actual engagement, changes in internal polls) were **fed back** into the process: user reactions served to further refine persuasion models, in a continuous optimization cycle.

**Delivery channels and A/B experimentation:** The main vehicle for CA's messages was **Facebook**. The company created targeted ads using Facebook's advertising system, which allowed ads to be directed to very specific demographic and psychographic clusters (by geographic area, interests, similar to a provided list). CA also leveraged Canadian partner **AggregateIQ** for campaigns on other platforms and the **display network** (e.g., targeted web banners): AIQ managed advertising spending for pro-Brexit and pro-Trump groups, using data and segments provided by CA [\[42\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=sharing%20of%20data%20in%20the,overseas%20elections%20in%20Chapter%206)[\[43\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=micro,uplift%20in%20voter). Furthermore, CA did not disdain traditional methods: in some cases, it provided _scripts_ for **telemarketing** or for political volunteers, calibrated to the profile of the voter to be contacted (e.g., emphasizing immigration when speaking with a "closed" and fearful subject, vs. economy with an "open" cosmopolitan). **A/B experiments** were central: **hundreds of ad variants** were tested simultaneously - changing, for example, color, emotional tone, call-to-action - measuring which version had the highest click-through or conversion rate in each segment [\[44\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=92,Some%20of%20the)[\[39\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=data%2C%20involving%20various%20organisations%20including,overseas%20elections%20in%20Chapter%206). A famous example reported by Wylie is the "Defeat Crooked Hillary" campaign in which CA allegedly tested dozens of anti-Clinton messages (from the most moderate to the most conspiratorial) to understand which resonated with groups of doubtful voters, then bombarding them with the optimized message. Facebook at that time **did not effectively track** these _dark ads_ nor limit their extreme personalization, which allowed CA to conduct a kind of propaganda laboratory invisible to the public and to the victims themselves.

**Integration with external data:** In addition to Facebook data, CA had a mosaic of other information. In the USA, it leveraged state **voter rolls** (containing voting history, party affiliation, etc.) and cross-referenced them with commercial datasets (from brokers like Acxiom, Experian) on purchasing habits, type of car owned, magazines read, charitable donations… [\[40\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=order%20to%20match%20the%20right,might%20support%20and%20how%20to). Nix stated that CA had "up to **5,000 datapoints per individual**" for American citizens, building a detailed picture of each voter's personality and preferences [\[40\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=order%20to%20match%20the%20right,might%20support%20and%20how%20to). This **hybrid strategy** (social media + offline data) allowed for the identification of unprecedented correlations - for example, discovering that pickup truck owners in North Carolina with few political "likes" but high conscientiousness scores were potential undecided Republican supporters. CA uploaded to Facebook not only user IDs collected by GSR but also lists of voters from specific counties obtained from parties or PAC committees, using **Custom Audiences** to reach them online with tailored messages. A further tool was **Lookalike Audiences**: starting from an audience whose orientation CA knew (e.g., people profiled as _pro-Trump_), Facebook's algorithm found other users with similar characteristics to extend the campaign to [\[38\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=3%20The%20issue%20of%20data,GSR%20and%20Cambridge%20Analytica%20allegations)[\[39\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=data%2C%20involving%20various%20organisations%20including,overseas%20elections%20in%20Chapter%206).

**Evidence of effectiveness and methodological limitations:** Measuring the concrete impact of CA's tactics is complex and highly debated. CA itself boasted some numerical results in the **2014 US Midterm** elections: in a race supported by the then _John Bolton Super PAC_, the use of psychographic profiles for micro-targeting advertising in 5 personality groups led - according to SCL - to a **39%** increase in _brand awareness_ of key issues among exposed voters [\[4\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=micro,turnout%2C%20for%20the%20targeted%20groups). Another campaign ("For America", 2014) aimed at mobilizing conservative online voters, again according to an internal SCL report, allegedly generated **1.5 million** targeted impressions, resulting in a surprising **+30% voter turnout** compared to expectations in the target groups [\[4\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=micro,turnout%2C%20for%20the%20targeted%20groups). These data, difficult to verify independently, aroused skepticism: the uplifts were calculated against non-transparent baselines and confounded with other factors (e.g., an increase in turnout could result from external causes, not just ads). Subsequent academic studies have downplayed the CA "mythology." For example, an analysis by Eitan Hersh (2019) to the US Senate concluded that **the persuasive effect of psychometric micro-targeting was probably modest**, as previous campaigns (Obama 2012) had already used similar data and models without miraculous results [\[45\]](https://www.judiciary.senate.gov/imo/media/doc/Professor%20Emma%20L.%20Briant%20Report%20on%20Cambrige%20Analytica.pdf#:~:text=,really%20championed%20by%20Obama%27s). Matthew Hindman noted that Kogan's model explained a portion of variance comparable to traditional models on age, sex, and race [\[5\]](https://www.niemanlab.org/2018/03/this-is-how-cambridge-analyticas-facebook-targeting-model-really-worked-according-to-the-person-who-built-it/#:~:text=In%20an%20email%20to%20me%2C,like%20race%2C%20age%2C%20and%20gender). Furthermore, internal **methodological limitations** undermined robustness: OCEAN scores deduced from likes have a margin of error and are static, while voter preferences evolve; the algorithm could therefore erroneously label subjects (e.g., mistaking a cynical young person for a persuadable undecided voter). There is also a **selection bias**: not all 87 million users were undecided voters - indeed many were already aligned, reducing the usefulness of convincing them. Even Christopher Wylie, the whistleblower, admitted that CA could not perform macro-level controlled tests on who voted what, so **there is no direct proof** that it "shifted" X decisive votes. Finally, a UK Commission report highlighted how the entire CA operation was **opaque and non-replicable**: the company refused to fully satisfy a Subject Access Request from a citizen, preventing them from knowing exactly what information it held about them and how it had used it [\[46\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=100,43)[\[47\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=101,119). This suggests a lack of rigor that casts doubt on the quality of CA's final product and makes it difficult to scientifically evaluate its impact.

**Outcomes and implications:** In 2018, the Cambridge Analytica scandal, which emerged thanks to investigations (_The Guardian_, _NY Times_) and the action of the UK Parliament, led to the closure of CA/SCL and a symbolic fine to Facebook (£500k from the UK ICO) for failing to protect data [\[48\]](https://now.tufts.edu/2018/05/17/did-cambridge-analytica-sway-election#:~:text=Tufts%20political%20scientist%20Eitan%20Hersh,a%20Senate%20Judiciary%20Committee%20hearing)[\[49\]](https://publications.parliament.uk/pa/cm201719/cmselect/cmcumeds/363/36306.htm#:~:text=conflicted%20with%20Mr%20Nix%E2%80%99s%20evidence%3B,as%20they%20were%20never%20enforced). The main legacy has been a global awakening to the risks of personal data abuse for **mass manipulation**. The tools refined by CA (psychological profiling + social media targeting) were not entirely new in themselves - but CA pushed their use beyond ethical limits, operating without transparency or informed consent from those concerned. The episode accelerated reforms: Facebook in 2018-19 further limited APIs and made political ads more controllable, while in the regulatory sphere, cases like this contributed to the drafting of guidelines (e.g., GDPR in the EU already provides for the right to object to profiling and automated decisions since 2018, although it was