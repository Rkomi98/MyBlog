# Inside a Container: Key Concepts

## Abstract
Second episode of the “Docker for Developers” series. This narrative guide walks through Docker’s core ideas with production-grade precision while staying approachable: the goal is to understand what Docker does conceptually before touching the CLI or writing manifests.

## 1. Core Concepts

*Figure 1: Docker architecture – the client talks to the Docker daemon, which manages images and containers. Images (for example Python, Redis) live in registries such as Docker Hub and can be pulled. Containers are runtime instances created from images and executed in isolation on the Docker host.*

**Docker image.** A Docker *image* is a **read‑only template** that describes everything required to spin up a container.[\[1\]](https://docs.docker.com/get-started/docker-overview/#:~:text=) It is effectively a snapshot of a minimal filesystem plus configuration. Images can build on top of other images (start from `ubuntu`, add Apache, your application, and its configuration).[\[1\]](https://docs.docker.com/get-started/docker-overview/#:~:text=) They are assembled incrementally: each image **is composed of multiple filesystem layers** stacked on top of one another (see section 4 for details).[\[2\]](https://docs.docker.com/get-started/docker-overview/#:~:text=You%20might%20create%20your%20own,compared%20to%20other%20virtualization%20technologies) Crucially, an image is static and immutable: it never changes at runtime and serves as the template from which containers are launched.

**Docker container.** A *container* is the **runtime instance of an image**.[\[3\]](https://docs.docker.com/get-started/docker-overview/#:~:text=) If the image is the blueprint, the container is the concrete object being executed. Practically speaking, a container is an isolated process on the host machine with its own filesystem, network stack, and process tree.[\[4\]](https://docs.docker.com/engine/containers/run/#:~:text=Docker%20runs%20processes%20in%20isolated,tree%20separate%20from%20the%20host) Docker uses the image as a base, creates a sandboxed environment, and runs your workload inside it. A helpful analogy is object-oriented programming: **the image behaves like a class; the container is an instance of that class**—the image defines, the container executes. You can create multiple containers from the same image (separate objects from one class) without them affecting one another; each keeps its own ephemeral state.[\[5\]](https://circleci.com/blog/docker-image-vs-container/#:~:text=An%20image%20is%20a%20snapshot,a%20container%20runs%20the%20software)

**Registry (image registry).** A *registry* is a central service used to store and share container images.[\[6\]](https://docs.docker.com/get-started/docker-overview/#:~:text=Docker%20registries) The default public registry is **Docker Hub**, which Docker consults automatically when an image is not available locally.[\[6\]](https://docs.docker.com/get-started/docker-overview/#:~:text=Docker%20registries) Organisations often rely on alternative public or private registries: GitHub Container Registry, Amazon ECR, Google GCR, Azure ACR, or self-hosted Harbor. Inside a registry, images are organised into repositories (for instance `username/image` on Docker Hub identifies a repository). Public registries expose images to anyone, often curated with “official” images; private registries restrict access and are ideal for proprietary or internal images. In both scenarios Docker can authenticate when required and then perform `pull` (download) and `push` (upload) operations.

**How an image is built.** Images are normally produced through a `docker build` process driven by a **Dockerfile**, a text file containing instructions that describe how to construct the image from a given base.[\[2\]](https://docs.docker.com/get-started/docker-overview/#:~:text=You%20might%20create%20your%20own,compared%20to%20other%20virtualization%20technologies) Each instruction (for example `FROM`, `RUN`, `COPY`) is executed sequentially by the Docker daemon during the build and produces an additional filesystem layer.[\[2\]](https://docs.docker.com/get-started/docker-overview/#:~:text=You%20might%20create%20your%20own,compared%20to%20other%20virtualization%20technologies) A sample Dockerfile might start with `FROM ubuntu:22.04` (base image), then `RUN apt-get install -y python3` (installs Python, creating a new layer with those files), followed by `COPY . /app` (copies the application into the image, adding another layer), and so on. Docker processes each instruction, “stacking” the results into the final image. The build leverages caching: if a step did not change, Docker reuses the existing layer instead of recomputing it, which makes rebuilds very fast.[\[2\]](https://docs.docker.com/get-started/docker-overview/#:~:text=You%20might%20create%20your%20own,compared%20to%20other%20virtualization%20technologies) The resulting image is identified by a **unique ID (a hash)** that you can run or distribute. You can craft images from scratch (for instance starting from `scratch`, an empty image) or extend existing ones, promoting reuse of common components rather than reinventing baseline systems.

**`docker pull` and `docker run`.** Two essential commands when consuming images are `docker pull` and `docker run`.

- **`docker pull`.** The command `docker pull <name:tag>` downloads an image from a registry. Behind the scenes the Docker client contacts the registry via HTTP(S) and requests the image manifest (a file listing the layers composing the image). It then downloads each layer (called *blobs*) that is not already cached, often in parallel, and stores them locally.[\[7\]](https://www.redhat.com/en/blog/pull-container-image#:~:text=When%20you%20initiate%20a%20pull%2C,a%20manifest%20from%20the%20registry) For example, `docker pull nginx:latest` fetches the list of layers for the Nginx image from Docker Hub and downloads them one by one; once complete, the image is ready on the host.
- **`docker run`.** The command `docker run` creates and starts a container from an image. It is conceptually equivalent to running `docker pull` (if the image is missing) followed by `docker container create` and `docker container start`.[\[8\]](https://docs.docker.com/get-started/docker-overview/#:~:text=When%20you%20run%20this%20command%2C,using%20the%20default%20registry%20configuration)[\[9\]](https://docs.docker.com/get-started/docker-overview/#:~:text=1,manually) When you execute `docker run ubuntu:22.04 echo "hello"`, Docker checks whether `ubuntu:22.04` exists locally; if not it pulls it from the registry.[\[9\]](https://docs.docker.com/get-started/docker-overview/#:~:text=1,manually) The daemon then **creates a container** (allocating resources, preparing a writable filesystem layer, assigning an ID) and **starts** it by executing the specified command (in this case `echo "hello"`). When the process finishes the container stops; you can restart it or remove it entirely. In short, `docker run` orchestrates the download (if needed), creation, and execution of the workload in one step—the most common command in daily Docker usage.[\[8\]](https://docs.docker.com/get-started/docker-overview/#:~:text=When%20you%20run%20this%20command%2C,using%20the%20default%20registry%20configuration)[\[9\]](https://docs.docker.com/get-started/docker-overview/#:~:text=1,manually)

## 2. Container Lifecycle

**From build to run (`docker run` under the hood).** After building an image you move to the *run* phase, meaning you create and execute containers based on it. When `docker run` is invoked, Docker may pull the image first (if required). Internally the daemon performs the equivalent of `docker container create`: the container enters the **Created** state, resources are allocated, an ID is assigned, and a container-specific filesystem is prepared.[\[9\]](https://docs.docker.com/get-started/docker-overview/#:~:text=1,manually) Docker then starts the container (similar to `docker container start`), launching the primary process defined in the image. At this point the container is in the **Running** state and executes the workload inside the isolated environment. The container stays running while that process is alive. When the process exits (voluntarily or due to a crash) or when you issue a stop command, Docker halts the container, which transitions to **Stopped/Exited**. A stopped container retains its isolated filesystem, logs, and state at the moment of shutdown and can be restarted. Finally, if you want to free the resources entirely you remove the container with `docker rm`, moving it to the **Removed** state: the container disappears from the host. The typical lifecycle therefore is **Created → Running → Stopped/Exited → Removed**.[\[10\]](https://last9.io/blog/docker-container-lifecycle/#:~:text=Every%20container%20typically%20goes%20through,general%20flow%20stays%20the%20same) (Docker also offers a **Paused** state in which the container’s processes are frozen via the cgroups freezer, allowing you to temporarily suspend CPU usage without terminating them.[\[11\]](https://last9.io/blog/docker-container-lifecycle/#:~:text=The%20Paused%20State) Pausing is less common; a container must be running to be paused and must be “unpaused” to resume.)

**Container states recap.** The key states a Docker container can occupy during its lifecycle are:[\[10\]](https://last9.io/blog/docker-container-lifecycle/#:~:text=Every%20container%20typically%20goes%20through,general%20flow%20stays%20the%20same)

- **Created.** The container definition and resources exist, but its process is not running yet. This happens via `docker create` or right after `docker run` before the workload starts. The container has an ID and filesystem but consumes minimal resources (no active process).
- **Running.** The container is active and its main process (PID 1 inside the container) is executing. It may expose network ports, consume CPU/RAM, and perform I/O—the “normal” state while serving applications.
- **Stopped/Exited.** The workload finished or the container was manually stopped. Nothing executes, yet the container still exists on the host with its filesystem intact. You can inspect it, read logs, or restart it. Containers that exit immediately because the command finishes also end up here.
- **Removed.** The container has been deleted from the host (`docker rm` or `docker run --rm`). It no longer appears in `docker ps -a` and no data remains (unless you used separate volumes). Any in-container changes that were not persisted externally are gone.

**Copy-on-write and container filesystems.** Docker relies on **copy-on-write** filesystems for containers. When a container is created Docker assembles a **union filesystem** composed of: all the image’s read-only layers plus a **container-specific writable layer**.[\[12\]](https://www.digitalocean.com/community/tutorials/working-with-docker-containers#:~:text=Images%20come%20to%20life%20with,are%20taken%20to%20preserve%20them) The container sees a single unified filesystem (its root filesystem) that merges the image layers and the writable layer. If a process modifies or creates a file, copy-on-write kicks in: if the file already existed in one of the image’s read-only layers, Docker **copies it into the writable layer** and applies the change there, keeping the original intact.[\[12\]](https://www.digitalocean.com/community/tutorials/working-with-docker-containers#:~:text=Images%20come%20to%20life%20with,are%20taken%20to%20preserve%20them) New files created by the container live solely in the writable layer. When you delete the container the writable layer disappears and those changes vanish (unless you mounted volumes to persist data). Conversely, you can inspect previous state by starting new containers from the same image: the read-only layers guarantee a clean, reproducible baseline every time.

## 3. Internal Architecture

**Isolation via namespaces and cgroups (Linux kernel).** Docker builds isolation on native Linux features—primarily *namespaces* and *cgroups*. **Namespaces** allow the kernel to isolate system views and resources for groups of processes. When Docker creates a container, the kernel assigns dedicated namespaces.[\[13\]](https://docs.docker.com/get-started/docker-overview/#:text=The%20underlying%20technology) Each namespace isolates a different aspect: the PID namespace gives the container its own process numbering (PID 1 inside the container is its main process, unaware of host processes),[\[14\]](https://blog.nginx.org/blog/what-are-namespaces-cgroups-how-do-they-work#:~:text=Namespaces%20and%20Containers)[\[15\]](https://blog.nginx.org/blog/what-are-namespaces-cgroups-how-do-they-work#:~:text=The%20crucial%20thing%20to%20notice,isolated%20within%20my%20own%20namespace) the network namespace provides a virtual network interface with its own IP stack, the mount namespace offers an isolated filesystem view, and so on. Additional namespaces handle IPC, hostname (UTS), and optionally user mappings (user namespaces let a container run as “root” inside while mapping to an unprivileged UID on the host). Thanks to namespaces each container lives in a logical bubble: **from the inside it only sees its own resources**, not those of other containers or the host.[\[14\]](https://blog.nginx.org/blog/what-are-namespaces-cgroups-how-do-they-work#:~:text=Namespaces%20and%20Containers) In parallel Docker leverages **cgroups** (control groups) to limit and monitor resource usage—CPU, memory, and I/O—for containers.[\[16\]](https://blog.nginx.org/blog/what-are-namespaces-cgroups-how-do-they-work#:~:text=What%20Are%20cgroups%3F) Cgroups let the system cap how much CPU or RAM a container may consume, preventing any single workload from starving others,[\[17\]](https://blog.nginx.org/blog/what-are-namespaces-cgroups-how-do-they-work#:~:text=A%20control%20group%20,of%20a%20collection%20of%20processes) provide resource accounting, and can freeze or terminate all container processes at once (for example `docker pause` uses the freezer cgroup).[\[11\]](https://last9.io/blog/docker-container-lifecycle/#:~:text=The%20Paused%20State)[\[18\]](https://blog.nginx.org/blog/what-are-namespaces-cgroups-how-do-they-work#:~:text=,cgroup%20with%20a%20single%20command) Summing up: **namespaces = isolation** (processes, network, filesystem); **cgroups = resource control**. Combined, they let Docker create environments that behave like separate systems even though they share the same Linux kernel.

**Logical vs physical isolation (containers vs VMs).** Container isolation is *logical/software* isolation rather than the *physical/hardware* isolation of traditional virtual machines. A container **shares the host’s kernel**: there is no separate OS instance per container, unlike a VM. Virtual machines virtualize an entire hardware stack and kernel, yielding stronger isolation at the cost of higher overhead; containers virtualize at the operating-system level, isolating processes and resources within the same kernel.[\[19\]](https://aws.amazon.com/compare/the-difference-between-containers-and-virtual-machines/#:~:text=Containers%20virtualize%20the%20operating%20system,give%20some%20more%20differences%20below) In practice, containers deliver process isolation through namespaces/cgroups, whereas VMs provide full machine isolation with separate guest kernels atop a hypervisor. This means a kernel vulnerability is shared between containers and the host (so kernel exploits can theoretically break out of a container), while on VMs the guest kernel is isolated from the host. Conversely containers are much lighter: **they start in seconds, consume only a few megabytes**, and dozens can run on a single host without major waste, whereas a small number of VMs might exhaust resources quickly.[\[20\]](https://circleci.com/blog/docker-image-vs-container/#:~:text=Since%20the%20container%20runs%20natively,you%20configure%20it%20that%20way)[\[21\]](https://aws.amazon.com/compare/the-difference-between-containers-and-virtual-machines/#:~:text=Containers%20virtualize%20the%20operating%20system,give%20some%20more%20differences%20below) Popular analogies liken containers to apartments in the same building (shared structure, isolated units) and VMs to detached houses (complete separation but higher cost).

## 4. Docker Images as Layers

**What a layer is and how it is stored.** A Docker image is not a single monolithic blob: it is a **stacked series of ordered layers**. Every *layer* represents a set of **filesystem changes** relative to the layer below it.[\[28\]](https://docs.docker.com/get-started/docker-concepts/building-images/understanding-image-layers/#:~:text=Each%20layer%20in%20an%20image,look%20at%20a%20theoretical%20image) Consider building an image for a Python application. The layers might look like this:[\[28\]](https://docs.docker.com/get-started/docker-concepts/building-images/understanding-image-layers/#:~:text=Each%20layer%20in%20an%20image,look%20at%20a%20theoretical%20image)

- **Layer 1:** Minimal base OS (core commands and the package manager on Ubuntu).
- **Layer 2:** Installation of the Python interpreter and `pip`.
- **Layer 3:** Addition of `requirements.txt`.
- **Layer 4:** Installation of the Python dependencies listed in `requirements.txt`.
- **Layer 5:** Copy of the application source code into the target directory.

In Dockerfile terms these correspond to `FROM ubuntu:22.04`, `RUN apt-get install python3 pip`, `COPY requirements.txt .`, `RUN pip install -r requirements.txt`, `COPY src/ .`. Docker creates a new layer for each instruction.[\[2\]](https://docs.docker.com/get-started/docker-overview/#:~:text=You%20might%20create%20your%20own,compared%20to%20other%20virtualization%20technologies) Internally, Docker stores each layer as a compressed archive (typically a tarball) identified by a SHA256 digest. On disk (for example under `/var/lib/docker/overlay2/` when using overlay2) each layer is extracted into its own directory.[\[29\]](https://www.adaltas.com/en/2021/06/03/linux-overlay-filesystem-docker/#:~:text=Docker%20uses%20the%20overlay%20filesystem,top%20of%20the%20image%20layers) Layers are **immutable**: once created they never change (any modification produces a brand-new layer). This design allows Docker to reuse unchanged layers when rebuilding images and only regenerate the ones that differ.[\[30\]](https://docs.docker.com/get-started/docker-overview/#:~:text=with%20a%20simple%20syntax%20for,compared%20to%20other%20virtualization%20technologies)[\[31\]](https://docs.docker.com/get-started/docker-overview/#:~:text=it,compared%20to%20other%20virtualization%20technologies)

**Layer caching and reuse.** Layered images enable heavy reuse across builds and across different images. If two images start from `ubuntu:22.04`, the base layer is shared: Docker downloads or builds it once and reuses it everywhere.[\[32\]](https://docs.docker.com/get-started/docker-concepts/building-images/understanding-image-layers/#:~:text=This%20is%20beneficial%20because%20it,look%20similar%20to%20the%20following) This drastically reduces disk space, bandwidth, and build times. During a build Docker computes the hash of the content produced at each step. When rebuilding, if a step is unchanged the cached layer is reused (you will see “Using cache” in the build output). If only the last instructions changed (for example the app code), Docker keeps the earlier layers and rebuilds the modified ones.[\[30\]](https://docs.docker.com/get-started/docker-overview/#:~:text=with%20a%20simple%20syntax%20for,compared%20to%20other%20virtualization%20technologies)[\[31\]](https://docs.docker.com/get-started/docker-overview/#:~:text=it,compared%20to%20other%20virtualization%20technologies) The same principle applies to `docker pull`: when pulling an updated image Docker downloads only the new layers and reuses the existing ones, saving time and bandwidth during deployments.

**Practical example.** Suppose you have a Dockerfile:

```
FROM ubuntu:22.04
RUN apt-get update && apt-get install -y nginx
COPY index.html /usr/share/nginx/html/index.html
```

During the build Docker executes:

- `FROM ubuntu:22.04`: instructs Docker to use the Ubuntu base image (it already consists of its own minimal layers). These become the **base layers** of the new image.
- `RUN apt-get update && apt-get install -y nginx`: Docker starts a temporary container from the base image, runs the commands, and captures the resulting filesystem changes (Nginx binaries, configuration files). Those changes form a **new layer** stacked on top.
- `COPY index.html ...`: Docker copies the local `index.html` file into the temporary container. The update becomes another **final layer**.

The resulting image contains the Ubuntu layers, a layer for the Nginx installation, and a layer with the HTML file. If you build another similar image (for example another static site on Ubuntu + Nginx) Docker reuses the Ubuntu and Nginx layers and adds only the delta with the new files. At runtime multiple containers can share the read-only layers, while per-container differences stay in their writable layers. Layered images therefore underpin Docker’s **portability** (download only what you need), **consistency** (each layer is immutable and reproducible), and **efficiency** (maximum reuse of shared components).

## 5. Registries and Distribution

**What happens during `docker pull`.** While we already described `docker pull`, let’s detail the flow. When you run `docker pull name:tag`, the client contacts the registry (Docker Hub by default, or another one specified in the reference) over HTTP APIs. The first step is requesting the image **manifest**—a JSON document listing the digests of all image layers plus metadata (configuration digest, architecture, etc.). The registry returns either a *manifest list* (also called an index, containing multiple manifests for different platforms) or a single manifest for a specific platform.[\[33\]](https://www.redhat.com/en/blog/pull-container-image#:~:text=There%20are%20currently%20two%20types,and%20a%20manifest)[\[34\]](https://www.redhat.com/en/blog/pull-container-image#:~:text=Pull%20a%20manifest) If a manifest list is returned, Docker chooses the manifest matching the host platform (for example `linux/amd64` on an x86_64 PC).[\[35\]](https://www.redhat.com/en/blog/pull-container-image#:~:text=Instead%20of%20blobs%2C%20the%20client,its%20operating%20system%20and%20architecture)[\[36\]](https://www.redhat.com/en/blog/pull-container-image#:~:text=Suppose%20a%20client%20chooses%20the,architecture%20and%20the%20manifest%20digest) Once the specific manifest is available, Docker **downloads the layers** listed there: for every layer digest it issues a GET request to fetch the corresponding blob.[\[7\]](https://www.redhat.com/en/blog/pull-container-image#:~:text=When%20you%20initiate%20a%20pull%2C,a%20manifest%20from%20the%20registry) Layers are downloaded in parallel and stored in the local cache (typically under `/var/lib/docker/` in the active storage driver). Layers already present are skipped. After all blobs have arrived, Docker assembles or updates the local image metadata (writing the config JSON and referencing the local layer digests). The image is now ready to run. From the user’s perspective you see “Pull complete” for each layer and “Downloaded newer image for name:tag”. Summarising, `docker pull` orchestrates **REST calls**: manifest (or multi-arch index) first, then the layer blobs.[\[37\]](https://www.redhat.com/en/blog/pull-container-image#:~:text=A%20Podman%20or%20Docker%20,image%20manifest%20is%20being%20pulled)

**Public vs private registries.** Public registries are open to everyone (subject to rate limits or authentication for pushing). They host official images, community builds, and shared artefacts. Security best practice is to pull only from trusted sources and verify image signatures (e.g. Docker Content Trust or Notary).[\[42\]](https://help.sonatype.com/en/docker-content-trust.html#:~:text=Docker%20Content%20Trust)[\[43\]](https://www.cncf.io/blog/2021/07/28/enforcing-image-trust-on-docker-containers-using-notary/#:~:text=match%20at%20L267%20thus%20improving,container%20image%20trust%20using%20Docker) Private registries, on the other hand, restrict access to authenticated users or service accounts. They are used to store internal images (for example corporate microservices), enforce vulnerability scanning, integrate with CI/CD, and host multi-architecture builds tailored to company infrastructure. Regardless of visibility the distribution protocol is the same: manifests and layers are transferred over HTTPS.

**`docker push` basics.** When you execute `docker push`, Docker performs the inverse flow. It authenticates with the registry, checks which layers the registry already owns, and uploads only the missing ones. The manifest—referencing the layer digests—is uploaded last. Pushing large images efficiently often involves keeping the number of layers small and arranging Dockerfile instructions so that rarely-changing layers stay near the top of the Dockerfile (allowing maximum cache reuse downstream). CI/CD pipelines usually push images tagged with semantic versions plus immutable digests to preserve traceability.

## 6. Conceptual Demo: What Happens When You `docker run nginx`

To consolidate the concepts, let’s walk through a **step-by-step narrative** of what happens when we execute:

```
docker run nginx
```

What happens behind the scenes after you press Enter?

1. **Image resolution.** The Docker client interprets `nginx` as `nginx:latest` on the default registry (Docker Hub). It queries Docker Hub to see whether that image exists. Unless a fresh copy already exists locally, the daemon downloads the official Nginx image.[\[9\]](https://docs.docker.com/get-started/docker-overview/#:~:text=1,manually) You will see progress bars for each layer (base Debian layer, Nginx binaries, etc.). After a few seconds `nginx:latest` is present on the host.
2. **Container creation.** Once the pull is complete, Docker prepares a new container from that image—equivalent to running `docker container create nginx:latest`. It allocates space for the container by creating a directory for its writable layer, assigns a unique identifier (e.g. `d64f1abcbc23`), opens the network plumbing (port 80 internally, though not yet published), and sets runtime parameters (entrypoint, default environment variables, working directory) as defined by the image. The container is now in the *Created* state: it exists but nothing has executed yet.[\[44\]](https://last9.io/blog/docker-container-lifecycle/#:~:text=The%20Created%20State) Docker has already built the container filesystem by overlaying the Nginx layers with a fresh writable layer.
3. **Isolation and resource wiring.** Before starting Nginx, Docker configures isolation. It applies a PID namespace (Nginx will see itself as PID 1), a network namespace (creating a virtual `eth0` linked to the host bridge network so Nginx only talks through that isolated channel), a mount namespace (the container sees its own filesystem root), and others.[\[13\]](https://docs.docker.com/get-started/docker-overview/#:~:text=The%20underlying%20technology) At the same time Docker wires default cgroup limits (by default containers can use host resources but are tracked in separate cgroups). Effectively Docker creates a dedicated execution bubble for Nginx.
4. **Process start inside the container.** Docker now *starts* the container—equivalent to `docker start`. That runs the image’s entrypoint. The official Nginx image defines the entrypoint as the Nginx daemon in foreground mode (typically `nginx -g "daemon off;"`). Docker executes that binary inside the isolated container. From the host you see a new process (e.g. `nginx: master process nginx -g 'daemon off;'` with some PID) belonging to the namespace-constrained environment. Inside the container the process is PID 1. Nginx loads its configuration (`/etc/nginx/nginx.conf`), opens port 80 *inside* the container, and starts listening. Because no port mapping was specified, Docker does not publish port 80 to the host; Nginx is reachable only from within the container or the internal bridge network. (`docker run -p 8080:80 nginx` would add a host-port mapping.)
5. **Container running state.** At this stage the Nginx container is in the **Running** state. `docker ps` shows the container ID with status “Up X seconds”. Nginx operates as if it were on its own machine: attaching a shell (`docker exec -it <container> bash`) reveals a filesystem focused on Nginx, a small set of running processes (master + workers), a hostname matching the container ID, and a network namespace with an address like `172.17.x.y`. Another developer running `docker run nginx` elsewhere would obtain the same environment instantly, showcasing portability.
6. **Stopping and removing.** When stopping the container you can either:
   - `docker stop <container>`: Docker sends `SIGTERM` to PID 1 inside the container (the Nginx master), waits the default grace period (10 seconds) and, if the process hasn’t exited, sends `SIGKILL`. The container transitions to Stopped and remains on disk (ready to restart with `docker start`).
   - `docker rm -f <container>`: Docker forcibly removes the container, first sending `SIGKILL` (if running) and then deleting the writable layer. With `--rm`, removal happens automatically once the process exits.

   The writable layer is deleted, while read-only layers remain available for future containers. Logs produced by the container live under `/var/lib/docker/containers/<id>/`; once removed they are gone unless you configured logging drivers or volumes.
7. **Inspecting and debugging.** While the container is running you can retrieve logs (`docker logs`), inspect configuration (`docker inspect`), check resource usage (`docker stats`), or enter the namespace (`docker exec`). These operations interact with the container without leaving the isolated environment; Docker handles the plumbing between host and container namespaces.

This walk-through illustrates how Docker orchestrates image distribution, filesystem assembly, Linux isolation primitives, and process management in a seamless developer experience.

---

**References**

[\[1\]](https://docs.docker.com/get-started/docker-overview/#:~:text=) Docker Docs – Docker overview  
[\[2\]](https://docs.docker.com/get-started/docker-overview/#:~:text=You%20might%20create%20your%20own,compared%20to%20other%20virtualization%20technologies) Docker Docs – Build images  
[\[3\]](https://docs.docker.com/get-started/docker-overview/#:~:text=) Docker Docs – What is a container  
[\[4\]](https://docs.docker.com/engine/containers/run/#:~:text=Docker%20runs%20processes%20in%20isolated,tree%20separate%20from%20the%20host) Docker Docs – Run a container  
[\[5\]](https://circleci.com/blog/docker-image-vs-container/#:~:text=An%20image%20is%20a%20snapshot,a%20container%20runs%20the%20software) CircleCI – Image vs container  
[\[6\]](https://docs.docker.com/get-started/docker-overview/#:~:text=Docker%20registries) Docker Docs – Registries  
[\[7\]](https://www.redhat.com/en/blog/pull-container-image#:~:text=When%20you%20initiate%20a%20pull%2C,a%20manifest%20from%20the%20registry) Red Hat – Pulling container images  
[\[8\]](https://docs.docker.com/get-started/docker-overview/#:~:text=When%20you%20run%20this%20command%2C,using%20the%20default%20registry%20configuration) Docker Docs – `docker run` explained  
[\[9\]](https://docs.docker.com/get-started/docker-overview/#:~:text=1,manually) Docker Docs – Pulling and running images  
[\[10\]](https://last9.io/blog/docker-container-lifecycle/#:~:text=Every%20container%20typically%20goes%20through,general%20flow%20stays%20the%20same) Last9 – Container lifecycle  
[\[11\]](https://last9.io/blog/docker-container-lifecycle/#:~:text=The%20Paused%20State) Last9 – Paused state  
[\[12\]](https://www.digitalocean.com/community/tutorials/working-with-docker-containers#:~:text=Images%20come%20to%20life%20with,are%20taken%20to%20preserve%20them) DigitalOcean – Working with Docker containers  
[\[13\]](https://docs.docker.com/get-started/docker-overview/#:~:text=The%20underlying%20technology) Docker Docs – Underlying technology  
[\[14\]](https://blog.nginx.org/blog/what-are-namespaces-cgroups-how-do-they-work#:~:text=Namespaces%20and%20Containers) NGINX – Namespaces overview  
[\[15\]](https://blog.nginx.org/blog/what-are-namespaces-cgroups-how-do-they-work#:~:text=The%20crucial%20thing%20to%20notice,isolated%20within%20my%20own%20namespace) NGINX – PID namespaces  
[\[16\]](https://blog.nginx.org/blog/what-are-namespaces-cgroups-how-do-they-work#:~:text=What%20Are%20cgroups%3F) NGINX – cgroups intro  
[\[17\]](https://blog.nginx.org/blog/what-are-namespaces-cgroups-how-do-they-work#:~:text=A%20control%20group%20,of%20a%20collection%20of%20processes) NGINX – Resource control  
[\[18\]](https://blog.nginx.org/blog/what-are-namespaces-cgroups-how-do-they-work#:~:text=,cgroup%20with%20a%20single%20command) NGINX – Managing cgroups  
[\[19\]](https://aws.amazon.com/compare/the-difference-between-containers-and-virtual-machines/#:~:text=Containers%20virtualize%20the%20operating%20system,give%20some%20more%20differences%20below) AWS – Containers vs VMs  
[\[20\]](https://circleci.com/blog/docker-image-vs-container/#:~:text=Since%20the%20container%20runs%20natively,you%20configure%20it%20that%20way) CircleCI – Performance considerations  
[\[21\]](https://aws.amazon.com/compare/the-difference-between-containers-and-virtual-machines/#:~:text=Containers%20virtualize%20the%20operating%20system,give%20some%20more%20differences%20below) AWS – Virtualization differences  
[\[28\]](https://docs.docker.com/get-started/docker-concepts/building-images/understanding-image-layers/#:~:text=Each%20layer%20in%20an%20image,look%20at%20a%20theoretical%20image) Docker Docs – Image layers  
[\[29\]](https://www.adaltas.com/en/2021/06/03/linux-overlay-filesystem-docker/#:text=Docker%20uses%20the%20overlay%20filesystem,top%20of%20the%20image%20layers) Adaltas – Overlay filesystem  
[\[30\]](https://docs.docker.com/get-started/docker-overview/#:~:text=with%20a%20simple%20syntax%20for,compared%20to%20other%20virtualization%20technologies) Docker Docs – Build caching  
[\[31\]](https://docs.docker.com/get-started/docker-overview/#:~:text=it,compared%20to%20other%20virtualization%20technologies) Docker Docs – Image reuse  
[\[32\]](https://docs.docker.com/get-started/docker-concepts/building-images/understanding-image-layers/#:~:text=This%20is%20beneficial%20because%20it,look%20similar%20to%20the%20following) Docker Docs – Benefits of layering  
[\[33\]](https://www.redhat.com/en/blog/pull-container-image#:~:text=There%20are%20currently%20two%20types,and%20a%20manifest) Red Hat – Manifest lists  
[\[34\]](https://www.redhat.com/en/blog/pull-container-image#:~:text=Pull%20a%20manifest) Red Hat – Pulling manifests  
[\[35\]](https://www.redhat.com/en/blog/pull-container-image#:~:text=Instead%20of%20blobs%2C%20the%20client,its%20operating%20system%20and%20architecture) Red Hat – Platform negotiation  
[\[36\]](https://www.redhat.com/en/blog/pull-container-image#:~:text=Suppose%20a%20client%20chooses%20the,architecture%20and%20the%20manifest%20digest) Red Hat – Selecting the right manifest  
[\[37\]](https://www.redhat.com/en/blog/pull-container-image#:~:text=A%20Podman%20or%20Docker%20,image%20manifest%20is%20being%20pulled) Red Hat – Registry downloads  
[\[42\]](https://help.sonatype.com/en/docker-content-trust.html#:~:text=Docker%20Content%20Trust) Sonatype – Docker Content Trust  
[\[43\]](https://www.cncf.io/blog/2021/07/28/enforcing-image-trust-on-docker-containers-using-notary/#:~:text=match%20at%20L267%20thus%20improving,container%20image%20trust%20using%20Docker) CNCF – Enforcing image trust  
[\[44\]](https://last9.io/blog/docker-container-lifecycle/#:~:text=The%20Created%20State) Last9 – Created state explained
