<!DOCTYPE html>
<html lang="it" translate="no">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AI nel banking: tra DPIA e AI Act | Mirko Calcaterra</title>
  <meta name="description" content="AI nel banking: tra DPIA e AI Act Abstract Il settore bancario sta adottando l&#39;IA in aree critiche come credit scoring, frodi e assistenza clienti, ma il perimetro normativo sta cambiando rapidamente. Questo articolo mette in relazione GDPR e AI Act, chiarend‚Ä¶">
  <meta name="author" content="Mirko Calcaterra">
  <link rel="canonical" href="https://rkomi98.github.io/MyBlog/blog/it/ai-banking-dpia-ai-act/">

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-9EVQ8G9W48"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-9EVQ8G9W48');
  </script>

  <!-- Open Graph -->
  <meta property="og:type" content="article">
  <meta property="og:url" content="https://rkomi98.github.io/MyBlog/blog/it/ai-banking-dpia-ai-act/">
  <meta property="og:title" content="AI nel banking: tra DPIA e AI Act">
  <meta property="og:description" content="AI nel banking: tra DPIA e AI Act Abstract Il settore bancario sta adottando l&#39;IA in aree critiche come credit scoring, frodi e assistenza clienti, ma il perimetro normativo sta cambiando rapidamente. Questo articolo mette in relazione GDPR e AI Act, chiarend‚Ä¶">
  <meta property="og:image" content="https://rkomi98.github.io/MyBlog/Assets/Logo.png">
  <meta property="article:published_time" content="2026-01-02T00:00:00.000Z">
  <meta property="article:author" content="Mirko Calcaterra">
  <meta property="article:section" content="Privacy">

  <!-- Twitter -->
  <meta property="twitter:card" content="summary_large_image">
  <meta property="twitter:title" content="AI nel banking: tra DPIA e AI Act">
  <meta property="twitter:description" content="AI nel banking: tra DPIA e AI Act Abstract Il settore bancario sta adottando l&#39;IA in aree critiche come credit scoring, frodi e assistenza clienti, ma il perimetro normativo sta cambiando rapidamente. Questo articolo mette in relazione GDPR e AI Act, chiarend‚Ä¶">
  <meta property="twitter:image" content="https://rkomi98.github.io/MyBlog/Assets/Logo.png">

  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "headline": "AI nel banking: tra DPIA e AI Act",
    "image": "https://rkomi98.github.io/MyBlog/Assets/Logo.png",
    "datePublished": "2026-01-02T00:00:00.000Z",
    "dateModified": "2026-01-02T11:40:55.464Z",
    "author": {
      "@type": "Person",
      "name": "Mirko Calcaterra",
      "url": "https://rkomi98.github.io/MyBlog/"
    },
    "publisher": {
      "@type": "Person",
      "name": "Mirko Calcaterra"
    },
    "description": "AI nel banking: tra DPIA e AI Act Abstract Il settore bancario sta adottando l&#39;IA in aree critiche come credit scoring, frodi e assistenza clienti, ma il perimetro normativo sta cambiando rapidamente. Questo articolo mette in relazione GDPR e AI Act, chiarend‚Ä¶"
  }
  </script>

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
  <style>
    * {
      box-sizing: border-box;
    }
    html {
      scroll-behavior: smooth;
    }
    body {
      margin: 0;
      font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
      background: radial-gradient(120% 120% at 50% 0%, rgba(59, 130, 246, 0.18) 0%, transparent 65%), var(--bg-primary);
      color: var(--text-primary);
      transition: background 0.3s ease, color 0.3s ease;
      --bg-primary: #0f172a;
      --bg-secondary: #111c33;
      --bg-card: rgba(15, 23, 42, 0.78);
      --bg-card-strong: rgba(15, 23, 42, 0.9);
      --border: rgba(148, 163, 184, 0.24);
      --text-primary: #e2e8f0;
      --text-secondary: #cbd5f5;
      --text-muted: #94a3b8;
      --accent: #60a5fa;
      --accent-strong: #38bdf8;
      --shadow-lg: 0 28px 60px -36px rgba(15, 23, 42, 0.9);
      --code-inline-bg: rgba(6, 11, 19, 0.92);
      --code-block-bg: #050912;
      --code-border: rgba(148, 163, 184, 0.35);
      --code-shadow: inset 0 0 0 1px rgba(148, 163, 184, 0.12);
      --code-text: #f8fafc;
    }
    body[data-theme="light"] {
      --bg-primary: #f8fafc;
      --bg-secondary: #ffffff;
      --bg-card: rgba(255, 255, 255, 0.96);
      --bg-card-strong: rgba(248, 250, 252, 0.98);
      --border: rgba(148, 163, 184, 0.18);
      --text-primary: #0f172a;
      --text-secondary: #334155;
      --text-muted: #64748b;
      --accent: #2563eb;
      --accent-strong: #1d4ed8;
      --shadow-lg: 0 28px 50px -38px rgba(15, 23, 42, 0.18);
      background: radial-gradient(120% 120% at 50% 0%, rgba(59, 130, 246, 0.12) 0%, transparent 60%), var(--bg-primary);
    }
    body[data-theme="light"] .post-toc {
      background: rgba(255, 255, 255, 0.96);
    }
    body[data-theme="light"] .post-body {
      background: rgba(255, 255, 255, 0.96);
      color: var(--text-secondary);
    }
    body[data-theme="light"] .post-hero__category {
      background: rgba(37, 99, 235, 0.12);
      color: var(--accent-strong);
    }
    body[data-theme="light"] .post-body blockquote {
      background: rgba(37, 99, 235, 0.1);
      color: var(--text-primary);
    }
    a {
      color: inherit;
      text-decoration: none;
    }
    header.site-header {
      position: sticky;
      top: 0;
      z-index: 12;
      backdrop-filter: blur(14px);
      background: rgba(15, 23, 42, 0.85);
      border-bottom: 1px solid var(--border);
      transition: background 0.3s ease;
    }
    body[data-theme="light"] header.site-header {
      background: rgba(248, 250, 252, 0.9);
    }
    .site-header__inner {
      max-width: 1200px;
      margin: 0 auto;
      padding: 1.15rem clamp(1.5rem, 3vw, 3rem);
      display: flex;
      align-items: center;
      justify-content: space-between;
      gap: 1.5rem;
    }
    .site-header__left {
      display: flex;
      align-items: center;
      gap: 1.75rem;
    }
    .logo {
      display: inline-flex;
      align-items: center;
      gap: 0.7rem;
      font-weight: 600;
      color: var(--text-primary);
      font-size: 1.05rem;
      letter-spacing: 0.01em;
    }
    .logo-img {
      width: 38px;
      height: 38px;
      border-radius: 12px;
      object-fit: cover;
      box-shadow: 0 8px 18px -12px rgba(15, 23, 42, 0.6);
    }
    .site-nav {
      display: flex;
      gap: 1.1rem;
      font-size: 0.95rem;
      font-weight: 500;
      color: var(--text-muted);
    }
    .site-nav a:hover {
      color: var(--accent);
    }
    .header-controls {
      display: flex;
      align-items: center;
      gap: 0.75rem;
    }
    .lang-btn {
      border: 1px solid var(--border);
      background: var(--bg-card);
      color: var(--text-primary);
      padding: 0.45rem 0.9rem;
      border-radius: 12px;
      font-weight: 600;
      cursor: pointer;
      transition: background 0.2s ease, color 0.2s ease, border 0.2s ease, transform 0.2s ease;
    }
    .lang-btn:hover:not(.lang-btn--disabled) {
      background: var(--accent);
      color: #ffffff;
      transform: translateY(-1px);
      border-color: transparent;
    }
    .lang-btn--disabled {
      opacity: 0.6;
      cursor: not-allowed;
    }
    .theme-toggle {
      position: relative;
      width: 52px;
      height: 28px;
      border-radius: 999px;
      border: 1px solid var(--border);
      background: var(--bg-card);
      cursor: pointer;
      padding: 0;
      transition: background 0.3s ease, border 0.3s ease;
      display: flex;
      align-items: center;
    }
    .theme-toggle .theme-thumb {
      position: absolute;
      top: 50%;
      left: 4px;
      transform: translateY(-50%);
      width: 22px;
      height: 22px;
      border-radius: 50%;
      background: #ffffff;
      color: #1f2937;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 0.9rem;
      transition: transform 0.3s ease, background 0.3s ease, color 0.3s ease;
      box-shadow: 0 6px 18px -8px rgba(15, 23, 42, 0.6);
    }
    body[data-theme="dark"] .theme-toggle .theme-thumb {
      transform: translate(20px, -50%);
      background: #1f2937;
      color: #f8fafc;
    }
    body[data-theme="dark"] .theme-toggle {
      background: rgba(37, 99, 235, 0.2);
      border-color: rgba(37, 99, 235, 0.3);
    }
    main.page {
      max-width: 1200px;
      margin: 0 auto;
      padding: 3.5rem clamp(1.5rem, 3vw, 3rem) 4.5rem;
    }
    .post-hero {
      position: relative;
      overflow: hidden;
      background: linear-gradient(135deg, rgba(99, 102, 241, 0.22) 0%, rgba(14, 165, 233, 0.08) 60%), var(--bg-card);
      border: 1px solid var(--border);
      border-radius: 28px;
      padding: 2.75rem;
      box-shadow: var(--shadow-lg);
      margin-bottom: 3rem;
    }
    .post-hero::after {
      content: '';
      position: absolute;
      inset: 0;
      background: radial-gradient(circle at 20% 20%, rgba(59, 130, 246, 0.22) 0%, transparent 55%);
      pointer-events: none;
    }
    .post-hero__icon {
      position: relative;
      font-size: 3.1rem;
      margin-bottom: 1.5rem;
      display: inline-flex;
      align-items: center;
      justify-content: center;
    }
    .post-hero__category {
      position: relative;
      display: inline-flex;
      align-items: center;
      justify-content: center;
      padding: 0.4rem 1rem;
      border-radius: 999px;
      background: rgba(15, 23, 42, 0.35);
      color: #ffffff;
      font-weight: 600;
      letter-spacing: 0.02em;
      margin-bottom: 1.25rem;
      text-transform: uppercase;
      font-size: 0.8rem;
    }
    .post-hero__title {
      position: relative;
      margin: 0 0 1.25rem;
      font-size: clamp(2.4rem, 4vw, 3.2rem);
      letter-spacing: -0.025em;
      line-height: 1.2;
      color: var(--text-primary);
    }
    .post-hero__meta {
      position: relative;
      display: flex;
      flex-wrap: wrap;
      gap: 1.25rem;
      color: var(--text-muted);
      font-size: 0.95rem;
      font-weight: 500;
    }
    .post-hero__meta span {
      display: inline-flex;
      align-items: center;
      gap: 0.45rem;
    }
    .post-layout {
      display: grid;
      grid-template-columns: minmax(220px, 300px) minmax(0, 1fr);
      gap: 2.75rem;
      align-items: flex-start;
    }
    .post-layout--single {
      grid-template-columns: minmax(0, 1fr);
    }
    .post-toc {
      background: var(--bg-card);
      border: 1px solid var(--border);
      border-radius: 22px;
      padding: 1.5rem 1.6rem 1.8rem;
      box-shadow: var(--shadow-lg);
      position: sticky;
      top: 120px;
      max-height: calc(100vh - 160px);
      overflow: hidden;
      display: flex;
      flex-direction: column;
    }
    .post-toc__header {
      display: flex;
      align-items: center;
      justify-content: space-between;
      gap: 0.75rem;
      margin-bottom: 0.5rem;
    }
    .post-toc__title {
      text-transform: uppercase;
      font-size: 0.78rem;
      letter-spacing: 0.18em;
      font-weight: 700;
      color: var(--text-muted);
    }
    .post-toc__toggle {
      display: none;
      border: 1px solid var(--border);
      background: transparent;
      color: var(--text-secondary);
      border-radius: 999px;
      padding: 0.25rem 0.8rem;
      font-size: 0.85rem;
      font-weight: 600;
      cursor: pointer;
      align-items: center;
      gap: 0.4rem;
      transition: background 0.2s ease, border 0.2s ease, color 0.2s ease;
    }
    .post-toc__toggle:hover {
      background: rgba(96, 165, 250, 0.15);
      border-color: transparent;
      color: var(--accent);
    }
    .post-toc__content {
      margin-top: 0.6rem;
      overflow-y: auto;
      padding-right: 0.4rem;
      transition: max-height 0.25s ease, opacity 0.25s ease;
      max-height: calc(100vh - 220px);
    }
    .post-toc--collapsed .post-toc__content {
      max-height: 0;
      opacity: 0;
      margin-top: 0;
      pointer-events: none;
    }
    .post-toc__list {
      list-style: none;
      margin: 0;
      padding: 0;
      display: flex;
      flex-direction: column;
      gap: 0.45rem;
    }
    .post-toc__sublist {
      margin-left: 0.85rem;
      padding-left: 0.85rem;
      border-left: 1px solid rgba(148, 163, 184, 0.35);
      margin-top: 0.4rem;
      gap: 0.35rem;
    }
    .post-toc__item {
      margin: 0;
    }
    .post-toc__link {
      color: var(--text-secondary);
      font-size: 0.95rem;
      line-height: 1.45;
      display: flex;
      align-items: flex-start;
      gap: 0.5rem;
      border-bottom: 1px dashed transparent;
      transition: color 0.2s ease, border-bottom 0.2s ease, transform 0.2s ease;
    }
    .post-toc__link:hover {
      color: var(--accent);
      border-bottom-color: rgba(96, 165, 250, 0.4);
      transform: translateX(2px);
    }
    .post-toc__link--active {
      color: var(--accent-strong);
      border-bottom-color: var(--accent-strong);
    }
    .post-toc__number {
      font-variant-numeric: tabular-nums;
      font-size: 0.85rem;
      color: var(--text-muted);
      min-width: 2.5ch;
      display: inline-flex;
      justify-content: flex-end;
      padding-top: 0.15rem;
    }
    .post-toc__text {
      flex: 1;
    }
    .post-body {
      background: var(--bg-card-strong);
      border: 1px solid var(--border);
      border-radius: 26px;
      padding: 2.5rem;
      box-shadow: var(--shadow-lg);
      font-size: 1.04rem;
      line-height: 1.75;
      color: var(--text-secondary);
    }
    .post-body h2 {
      margin-top: 2.75rem;
      margin-bottom: 1.25rem;
      font-size: clamp(1.9rem, 3vw, 2.35rem);
      color: var(--text-primary);
      letter-spacing: -0.01em;
    }
    .post-body h3 {
      margin-top: 2.2rem;
      margin-bottom: 1rem;
      font-size: 1.5rem;
      color: var(--text-primary);
    }
    .post-body h4 {
      margin-top: 1.8rem;
      margin-bottom: 0.75rem;
      font-size: 1.2rem;
      color: var(--text-primary);
    }
    .post-body p {
      margin-bottom: 1.4rem;
    }
    .post-body .post-warning {
      margin: 2rem 0;
      border-radius: 18px;
      border: 1px solid rgba(250, 204, 21, 0.35);
      background: rgba(254, 243, 199, 0.9);
      color: #4a3b0a;
      padding: 0 1.25rem 1rem;
      box-shadow: inset 0 0 0 1px rgba(255, 255, 255, 0.35);
    }
    body[data-theme="dark"] .post-body .post-warning {
      background: rgba(253, 230, 138, 0.12);
      border-color: rgba(251, 191, 36, 0.5);
      color: #f6e6b2;
      box-shadow: inset 0 0 0 1px rgba(250, 200, 88, 0.3);
    }
    .post-body .post-warning summary {
      list-style: none;
      cursor: pointer;
      font-weight: 600;
      display: flex;
      align-items: center;
      gap: 0.5rem;
      padding: 1rem 0;
      color: inherit;
    }
    .post-body .post-warning summary::-webkit-details-marker {
      display: none;
    }
    .post-body .post-warning summary::before {
      content: '‚ö†Ô∏è';
      font-size: 1rem;
    }
    .post-body .post-warning[open] {
      padding-bottom: 1.25rem;
    }
    .post-body .post-warning p:last-child {
      margin-bottom: 0;
    }
    .post-body ul,
    .post-body ol {
      margin: 1.4rem 0 1.4rem 1.4rem;
      padding: 0;
    }
    .post-body li {
      margin-bottom: 0.8rem;
    }
    .post-body a {
      color: var(--accent);
      text-decoration: none;
      border-bottom: 1px solid rgba(96, 165, 250, 0.35);
      transition: color 0.2s ease, border-bottom 0.2s ease;
    }
    .post-body a:hover {
      color: var(--accent-strong);
      border-bottom-color: var(--accent-strong);
    }
    .post-body blockquote {
      margin: 2rem 0;
      padding: 1.5rem 1.75rem;
      border-left: 4px solid var(--accent);
      border-radius: 0 18px 18px 0;
      background: rgba(37, 99, 235, 0.12);
      color: var(--text-primary);
    }
    .post-body code {
      background: var(--code-inline-bg);
      color: var(--code-text);
      padding: 0.2rem 0.45rem;
      border-radius: 6px;
      font-family: 'JetBrains Mono', 'Fira Code', monospace;
      font-size: 0.9rem;
    }
    .post-body pre code {
      background: transparent;
      padding: 0;
      display: block;
      font-size: inherit;
      line-height: inherit;
    }
    .hljs {
      color: #e2e8f0;
      background: transparent;
    }
    .hljs-comment,
    .hljs-quote {
      color: #7dd79d;
      font-style: italic;
    }
    .hljs-keyword,
    .hljs-selector-tag,
    .hljs-literal,
    .hljs-name,
    .hljs-strong,
    .hljs-built_in {
      color: #7dd3fc;
      font-weight: 600;
    }
    .hljs-title,
    .hljs-section,
    .hljs-function,
    .hljs-meta .hljs-keyword {
      color: #38bdf8;
      font-weight: 600;
    }
    .hljs-string,
    .hljs-doctag,
    .hljs-addition,
    .hljs-attribute,
    .hljs-template-tag,
    .hljs-template-variable {
      color: #facc15;
    }
    .hljs-number,
    .hljs-symbol,
    .hljs-bullet,
    .hljs-link,
    .hljs-meta,
    .hljs-type {
      color: #f472b6;
    }
    .hljs-variable,
    .hljs-params {
      color: #cbd5f5;
    }
    .post-body pre {
      background: var(--code-block-bg);
      color: var(--code-text);
      padding: 1.2rem 1.4rem;
      padding-right: 3.6rem;
      border-radius: 18px;
      overflow-x: auto;
      font-family: 'JetBrains Mono', 'Fira Code', monospace;
      font-size: 0.95rem;
      box-shadow: var(--code-shadow);
      border: 1px solid var(--code-border);
      margin: 2rem 0;
      position: relative;
    }
    .code-copy-btn {
      position: absolute;
      top: 0.75rem;
      right: 0.75rem;
      background: rgba(15, 23, 42, 0.8);
      color: #e2e8f0;
      border: 1px solid rgba(148, 163, 184, 0.35);
      border-radius: 999px;
      padding: 0.25rem 0.85rem;
      font-size: 0.85rem;
      font-weight: 600;
      display: inline-flex;
      align-items: center;
      gap: 0.35rem;
      cursor: pointer;
      transition: background 0.2s ease, color 0.2s ease, border-color 0.2s ease, transform 0.2s ease;
    }
    .code-copy-btn:hover {
      background: rgba(96, 165, 250, 0.85);
      color: #ffffff;
      border-color: transparent;
      transform: translateY(-1px);
    }
    .code-copy-btn--copied {
      background: rgba(34, 197, 94, 0.85);
      color: #ffffff;
      border-color: transparent;
    }
    .code-copy-btn__icon {
      font-size: 0.95rem;
    }
    .code-copy-btn__text {
      display: inline-block;
    }
    body[data-theme="light"] .code-copy-btn {
      background: rgba(248, 250, 252, 0.85);
      color: #0f172a;
      border-color: rgba(148, 163, 184, 0.4);
    }
    body[data-theme="light"] .code-copy-btn--copied {
      background: rgba(34, 197, 94, 0.92);
      color: #ffffff;
    }
    .post-body img {
      max-width: 100%;
      border-radius: 18px;
      margin: 2.2rem 0;
      box-shadow: 0 24px 45px -28px rgba(15, 23, 42, 0.55);
    }
    .post-body .table-wrapper {
      margin: 2rem 0;
      border-radius: 18px;
      border: 1px solid var(--border);
      background: rgba(15, 23, 42, 0.55);
      box-shadow: inset 0 0 0 1px rgba(148, 163, 184, 0.12);
      position: relative;
      overflow: hidden;
    }
    .post-body .table-wrapper__scroll {
      overflow-x: auto;
      -webkit-overflow-scrolling: touch;
    }
    .post-body .table-wrapper__scroll::-webkit-scrollbar {
      height: 10px;
    }
    .post-body .table-wrapper__scroll::-webkit-scrollbar-thumb {
      background: rgba(96, 165, 250, 0.4);
      border-radius: 999px;
    }
    .post-body .table-wrapper table {
      width: 100%;
      border-collapse: collapse;
      background: transparent;
    }
    .post-body .table-wrapper[data-table-size="medium"] table {
      min-width: 720px;
    }
    .post-body .table-wrapper[data-table-size="wide"] table {
      min-width: 960px;
    }
    .post-body .table-wrapper thead th {
      background: rgba(96, 165, 250, 0.12);
      color: var(--text-primary);
      font-weight: 600;
    }
    .post-body .table-wrapper th,
    .post-body .table-wrapper td {
      padding: 0.9rem 1rem;
      text-align: left;
      border-bottom: 1px solid rgba(148, 163, 184, 0.18);
      white-space: nowrap;
    }
    .post-body .table-wrapper td {
      white-space: normal;
    }
    .post-body .table-wrapper tr:last-child td {
      border-bottom: none;
    }
    .post-body .table-wrapper__expand {
      position: absolute;
      top: 0.75rem;
      right: 0.75rem;
      background: rgba(15, 23, 42, 0.85);
      border: 1px solid rgba(148, 163, 184, 0.3);
      color: var(--accent);
      border-radius: 999px;
      padding: 0.35rem 0.9rem;
      font-size: 0.85rem;
      font-weight: 600;
      display: inline-flex;
      align-items: center;
      gap: 0.35rem;
      cursor: pointer;
      transition: background 0.2s ease, color 0.2s ease, transform 0.2s ease;
      z-index: 2;
    }
    .post-body .table-wrapper__expand:hover {
      background: rgba(37, 99, 235, 0.35);
      color: #ffffff;
      transform: translateY(-1px);
      border-color: transparent;
    }
    .table-overlay {
      position: fixed;
      inset: 0;
      background: rgba(15, 23, 42, 0.85);
      backdrop-filter: blur(6px);
      display: none;
      align-items: center;
      justify-content: center;
      padding: 2rem;
      z-index: 999;
    }
    .table-overlay--visible {
      display: flex;
    }
    .table-overlay__content {
      background: var(--bg-card-strong);
      border: 1px solid var(--border);
      border-radius: 24px;
      max-width: min(1080px, 92vw);
      max-height: 85vh;
      width: 100%;
      box-shadow: 0 32px 80px -40px rgba(15, 23, 42, 0.9);
      position: relative;
      overflow: hidden;
    }
    .table-overlay__close {
      position: absolute;
      top: 0.85rem;
      right: 0.85rem;
      background: rgba(15, 23, 42, 0.9);
      border: 1px solid rgba(148, 163, 184, 0.35);
      color: var(--text-primary);
      border-radius: 999px;
      padding: 0.4rem 1rem;
      font-size: 0.9rem;
      font-weight: 600;
      cursor: pointer;
      transition: background 0.2s ease, color 0.2s ease;
    }
    .table-overlay__close:hover {
      background: rgba(37, 99, 235, 0.4);
      color: #ffffff;
      border-color: transparent;
    }
    .table-overlay__scroll {
      overflow: auto;
      max-height: 85vh;
      padding: 2.5rem 2rem 2rem;
    }
    .table-overlay__scroll table {
      width: 100%;
      border-collapse: collapse;
      background: transparent;
    }
    .table-overlay__scroll table[data-table-size="medium"] {
      min-width: 720px;
    }
    .table-overlay__scroll table[data-table-size="wide"] {
      min-width: 960px;
    }
    .table-overlay__scroll thead th {
      background: rgba(96, 165, 250, 0.12);
      color: var(--text-primary);
      font-weight: 600;
    }
    .table-overlay__scroll th,
    .table-overlay__scroll td {
      padding: 0.9rem 1rem;
      text-align: left;
      border-bottom: 1px solid rgba(148, 163, 184, 0.18);
      white-space: nowrap;
    }
    .table-overlay__scroll td {
      white-space: normal;
    }
    .table-overlay__scroll tr:last-child td {
      border-bottom: none;
    }
    body[data-theme="light"] .post-body .table-wrapper {
      background: rgba(255, 255, 255, 0.96);
      box-shadow: inset 0 0 0 1px rgba(148, 163, 184, 0.16);
    }
    body[data-theme="light"] .post-body .table-wrapper__expand {
      background: rgba(248, 250, 252, 0.9);
    }
    body[data-theme="light"] .table-overlay {
      background: rgba(15, 23, 42, 0.25);
    }
    body[data-theme="light"] .table-overlay__content {
      background: rgba(255, 255, 255, 0.98);
    }
    body.no-scroll {
      overflow: hidden;
    }
    footer {
      margin-top: 4rem;
      padding: 2rem 0;
      text-align: center;
      color: var(--text-muted);
      font-size: 0.92rem;
      border-top: 1px solid var(--border);
      background: rgba(15, 23, 42, 0.35);
    }
    body[data-theme="light"] footer {
      background: rgba(255, 255, 255, 0.72);
    }
    @media (max-width: 1024px) {
      .site-header__inner {
        padding: 1rem clamp(1.25rem, 4vw, 2rem);
      }
      main.page {
        padding: 2.75rem clamp(1.25rem, 4vw, 2rem) 4rem;
      }
      .post-layout {
        grid-template-columns: minmax(0, 1fr);
      }
      .post-toc {
        position: sticky;
        top: 88px;
        z-index: 6;
        max-height: calc(100vh - 140px);
        margin-bottom: 2rem;
        padding: 1.1rem 1.25rem 1.35rem;
      }
      .post-toc__toggle {
        display: inline-flex;
      }
      .post-toc__content {
        max-height: none;
        margin-top: 0.4rem;
        overflow: visible;
      }
    }
    @media (max-width: 720px) {
      .post-hero {
        padding: 2.1rem 1.65rem;
      }
      .post-body {
        padding: 1.9rem 1.5rem;
      }
      .site-header__inner {
        flex-direction: column;
        align-items: stretch;
        gap: 1rem;
      }
      .site-header__left {
        justify-content: space-between;
      }
      .header-controls {
        align-self: flex-end;
      }
      .post-hero__title {
        font-size: clamp(2rem, 6vw, 2.6rem);
      }
      .post-body .table-wrapper {
        margin: 1.6rem 0;
      }
      .post-body .table-wrapper__expand {
        top: 0.6rem;
        right: 0.6rem;
        font-size: 0.78rem;
        padding: 0.25rem 0.75rem;
      }
      .table-overlay__scroll {
        padding: 1.8rem 1.25rem 1.5rem;
      }
    }
  </style>
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
      },
    };
  </script>
  <script id="mathjax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
</head>
<body data-theme="dark">
  <header class="site-header">
    <div class="site-header__inner">
      <div class="site-header__left">
        <a class="logo" href="../../../index.html">
          <img src="../../../Assets/Logo.png" alt="Mirko Calcaterra logo" class="logo-img">
          <span class="logo-text">Mirko Calcaterra</span>
        </a>
        <nav class="site-nav">
          <a href="../../../index.html" data-it="Home" data-en="Home">Home</a>
          <a href="../../../blog/index.html" data-it="Blog" data-en="Blog">Blog</a>
        </nav>
      </div>
      <div class="header-controls">
        <button class="lang-btn" type="button">EN</button>
        <button class="theme-toggle" type="button" aria-label="Toggle theme">
          <span class="theme-thumb">‚òÄÔ∏è</span>
        </button>
      </div>
    </div>
  </header>
  <main class="page">
    <article class="post">
      <section class="post-hero">
        <div class="post-hero__icon">üõ°Ô∏è</div>
        <span class="post-hero__category">Privacy</span>
        <h1 class="post-hero__title">AI nel banking: tra DPIA e AI Act</h1>
        <div class="post-hero__meta">
          <span>üìÖ 2 gennaio 2026</span>
          <span>‚è±Ô∏è 26 min</span>
        </div>
      </section>
      <section class="post-layout">
        <aside class="post-toc" data-collapsed="false">
        <div class="post-toc__header">
          <div class="post-toc__title" data-it="Indice" data-en="Table of contents">Indice</div>
          <button class="post-toc__toggle" type="button" aria-expanded="true" aria-label="Nascondi indice">
            <span class="post-toc__toggle-text">Indice</span>
            <span class="post-toc__toggle-icon" aria-hidden="true">‚ñæ</span>
          </button>
        </div>
        <div class="post-toc__content">
          <ul class="post-toc__list">
    <li class="post-toc__item" data-depth="0">
          <a class="post-toc__link" href="#abstract">
            <span class="post-toc__number">1</span>
            <span class="post-toc__text">Abstract</span>
          </a>
          
        </li><li class="post-toc__item" data-depth="0">
          <a class="post-toc__link" href="#introduzione">
            <span class="post-toc__number">2</span>
            <span class="post-toc__text">Introduzione</span>
          </a>
          
        </li><li class="post-toc__item" data-depth="0">
          <a class="post-toc__link" href="#cosa-dicono-le-regole-e-come-muoversi">
            <span class="post-toc__number">3</span>
            <span class="post-toc__text">Cosa dicono le regole e come muoversi</span>
          </a>
          <ul class="post-toc__list post-toc__sublist">
    <li class="post-toc__item" data-depth="1">
          <a class="post-toc__link" href="#principali-evidenze">
            <span class="post-toc__number">3.1</span>
            <span class="post-toc__text">Principali evidenze</span>
          </a>
          
        </li><li class="post-toc__item" data-depth="1">
          <a class="post-toc__link" href="#principali-ambiguit-normative">
            <span class="post-toc__number">3.2</span>
            <span class="post-toc__text">Principali ambiguit√† normative</span>
          </a>
          
        </li><li class="post-toc__item" data-depth="1">
          <a class="post-toc__link" href="#implicazioni-operative-per-un-mvp">
            <span class="post-toc__number">3.3</span>
            <span class="post-toc__text">Implicazioni operative per un MVP</span>
          </a>
          
        </li><li class="post-toc__item" data-depth="1">
          <a class="post-toc__link" href="#evidence-table">
            <span class="post-toc__number">3.4</span>
            <span class="post-toc__text">Evidence Table</span>
          </a>
          
        </li>
  </ul>
        </li><li class="post-toc__item" data-depth="0">
          <a class="post-toc__link" href="#questioni-residue-aperte">
            <span class="post-toc__number">4</span>
            <span class="post-toc__text">Questioni Residue Aperte</span>
          </a>
          
        </li>
  </ul>
        </div>
      </aside>
        <div class="post-body">
          <h2 id="abstract">Abstract</h2>
<p>Il settore bancario sta adottando l&#39;IA in aree critiche come credit scoring, frodi e assistenza clienti, ma il perimetro normativo sta cambiando rapidamente. Questo articolo mette in relazione GDPR e AI Act, chiarendo quando scattano DPIA e FRIA e quali obblighi operativi ne derivano. L&#39;obiettivo √® offrire una mappa pratica per valutare i rischi, distinguere i casi ad alto rischio e impostare una governance coerente.</p>
<h2 id="introduzione">Introduzione</h2>
<p>L&#39;adozione dell&#39;IA in banca non √® piu&#39; sperimentale: √® gi√† parte di processi che toccano diritti, accesso al credito e tutela dei dati. Prima di addentrarci nelle regole, serve un quadro introduttivo che colleghi i principali casi d&#39;uso ai due pilastri regolatori (GDPR e AI Act) e alle valutazioni di impatto richieste. Questo articolo fa da ponte tra tecnologia e compliance, per orientare fin da subito le scelte di progetto.</p>
<h2 id="cosa-dicono-le-regole-e-come-muoversi">Cosa dicono le regole e come muoversi</h2>
<h3 id="principali-evidenze">Principali evidenze</h3>
<p>Le nuove regole europee sull&#39;AI (Reg. UE 2024/1689, &quot;AI Act&quot;) classificano come <em>&quot;sistemi ad alto rischio&quot;</em> diversi impieghi dell&#39;Intelligenza Artificiale (IA) nel settore bancario, imponendo requisiti stringenti<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=utilizzati%20per%20valutare%20il%20merito,previsti%20dal%20diritto%20dell%27Unione%20al">[1]</a>. </p>
<p>In particolare, l&#39;uso dell&#39;AI per valutare l&#39;affidabilit√† creditizia (credit scoring) di persone fisiche rientra nell&#39;Allegato III ed √® quindi considerato <em>high-risk</em><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=utilizzati%20per%20valutare%20il%20merito,previsti%20dal%20diritto%20dell%27Unione%20al">[1]</a>. Analogamente, i sistemi IA impiegati nel processo di <strong>reclutamento e gestione del personale</strong> (es. selezione candidati, decisioni di assunzione o promozione) sono esplicitamente elencati tra gli usi ad alto rischio, dato il potenziale impatto sui diritti dei lavoratori e il rischio di discriminazioni<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=i%20sistemi%20di%20IA%20destinati,o%C2%A0filtrare%20le%20candidature%20e%C2%A0valutare%20i%C2%A0candidati">[2]</a>. </p>
<p>Altri casi d&#39;uso tipici in banca - come sistemi di <strong>chatbot o assistenti virtuali per clienti</strong>, strumenti di <strong>anti-riciclaggio (AML) e rilevazione frodi</strong>, sistemi di <strong>verifica identit√† (KYC)</strong> con riconoscimento biometrico, ecc. - pur non tutti ricadendo in categorie &quot;alto rischio&quot; per l&#39;AI Act, comportano comunque significativi obblighi di conformit√†. In particolare, l&#39;AI Act esenta dal novero <em>high-risk</em> i sistemi IA usati per individuare frodi finanziarie o per calcoli patrimoniali prudenziali<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=i%20sistemi%20di%20IA%20previsti,ad%20alto%20rischio%20ai%20sensi">[3]</a>; ci√≤ significa che, paradossalmente, algoritmi di <strong>fraud detection</strong> o di <strong>monitoraggio transazioni sospette AML</strong> non sono soggetti ai requisiti di alto rischio dell&#39;AI Act, pur dovendo rispettare la normativa di settore (es. antiriciclaggio) e privacy. </p>
<blockquote>
<p>Resta fermo, in ogni caso, l&#39;obbligo per le banche di effettuare una valutazione caso-per-caso: ad esempio, un sistema di IA bancario che, pur non rientrando espressamente nell&#39;Allegato III, presenti rischi significativi per diritti, sicurezza o accesso a servizi essenziali potrebbe essere prudentemente trattato come <em>alto rischio</em> ai fini interni.</p>
</blockquote>
<p>Le fonti regolamentari primarie delineano una serie di <strong>checklist obbligatorie</strong> e buone pratiche applicabili. Sul versante privacy, il GDPR impone la <strong>Data Protection Impact Assessment (DPIA)</strong> per trattamenti con rischio elevato, e le autorit√† (EDPB e Garante Privacy) hanno elencato criteri e casi tipici: ad esempio, profilazione o scoring su larga scala, decisioni automatizzate con effetti significativi (come concessione di un prestito), monitoraggio sistematico di utenti, uso di dati sensibili o di tecnologie innovative come l&#39;IA<a href="https://www.latuaprivacy.com/site/approfondimenti/16-la-valutazione-d-impatto#:~:text=la%20concessione%20di%20un%20finanziamento">[5]</a>. </p>
<p>Molti use case di IA bancari soddisfano tali criteri come per esempio:</p>
<ul>
<li>credit scoring = profilazione finanziaria con impatto su diritti;</li>
<li>monitoraggio transazioni = controllo sistematico;</li>
<li>riconoscimento facciale = dato biometrico;</li>
</ul>
<blockquote>
<p><em>Questi richiedono quindi una valutazione preventiva d&#39;impatto sulla privacy (DPIA)</em> </p>
</blockquote>
<p>In parallelo, l&#39;AI Act introduce per gli utilizzatori (<em>deployers</em>) di sistemi AI ad alto rischio l&#39;obbligo di condurre una <strong>Valutazione d&#39;Impatto sui Diritti Fondamentali (FRIA)</strong> prima della messa in uso<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=una%20descrizione%20dei%20processi%20del,con%20la%20sua%20finalit%C3%A0%20prevista">[7]</a>. </p>
<p>In ambito bancario ci√≤ riguarda in particolare gli enti che impiegano sistemi di AI Act Annex III, ad esempio le banche che usano IA per credit scoring (Allegato III ¬ß5(b)) o per decisioni su polizze vita/sanitarie. Tale FRIA deve considerare contesto d&#39;uso, categorie di interessati coinvolti, rischi per diritti (es. bias, esclusione), misure di controllo umano previste e azioni di rimedio<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=Obblighi%20dei%20fornitori%20di%20modelli%20di%20IA%20per%20finalit%C3%A0%20generali%20con%20rischio%20sistemico,%20In%20aggiunta">[8]</a>. Va notificata all&#39;autorit√† di vigilanza di mercato competente con i relativi risultati<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=obbligo%20di%20notifica">[9]</a>, inserendosi quindi come adempimento formale prima dell&#39;uso del sistema.</p>
<p>Un tema chiave emerso √® la <strong>sovrapposizione e distinzione</strong> tra DPIA (focalizzata sui rischi privacy GDPR) e FRIA (focalizzata su impatti <em>etici e diritti fondamentali</em> pi√π ampi). In caso di sistemi IA che trattano dati personali, il legislatore prevede che la FRIA <em>si integri</em> con la DPIA gi√† svolta, evitando duplicazioni: in pratica, la <strong>DPIA copre privacy e sicurezza dati</strong>, mentre la <strong>FRIA estende l&#39;analisi a discriminazione, accesso equo a servizi, trasparenza verso gli interessati</strong>, ecc. </p>
<p>Ad esempio, per un algoritmo di concessione prestiti, la DPIA valuter√† liceit√† e proporzionalit√† del trattamento dati, minimizzazione, misure di sicurezza e anonimizzazione; la FRIA aggiunger√† la valutazione dei rischi di <em>bias algoritmico</em>, impatto socio-economico (es. esclusione finanziaria di gruppi vulnerabili) e l&#39;adeguatezza delle misure di <strong>human oversight</strong> adottate. Quest&#39;ultimo punto, la supervisione umana, ricorre come principio basilare: tanto il GDPR (art.22) quanto l&#39;AI Act e le linee guida di settore insistono sulla necessit√† che l&#39;IA <em>non prenda decisioni completamente autonome senza possibilit√† di intervento umano</em>. </p>
<p>Le <strong>Linee Guida EBA 2020 sul governo del credito</strong> hanno chiarito che l&#39;uso di modelli automatizzati √® consentito solo entro confini precisi, includendo <em>trasparenza, tracciabilit√†, supervisione costante ed evitando ogni forma di discriminazione</em><a href="https://paradigma.it/2025/10/21/ai-concessione-credito-responsabilita/#:~:text=Le%20Linee%20Guida%20EBA%20del,supervisione%20costante">[11]</a>. </p>
<p>Allo stesso modo, Banca d&#39;Italia ha ribadito che l&#39;IA pu√≤ supportare la valutazione del rischio creditizio <em>ma non sostituire il giudizio umano</em>: la banca rimane responsabile ultima di correttezza e legittimit√† delle decisioni<a href="https://paradigma.it/2025/10/21/ai-concessione-credito-responsabilita/#:~:text=La%20Banca%20d'Italia,%E2%80%9Cal%20posto%E2%80%9D%20del%20giudizio%20dell%E2%80%99intermediario">[12]</a>. </p>
<p><strong>L&#39;imprescindibilit√† del controllo umano</strong> √® sancita anche a livello di principi internazionali: vi √® ampia convergenza sull&#39;importanza di mantenere un intervento umano significativo (&quot;human-in-the-loop&quot;) nei processi decisionali automatizzati, per garantire accountability e tutela dei diritti<a href="https://www.bancaditalia.it/pubblicazioni/qef/2022-0721/QEF_721_IT.pdf#:~:text=convergenza%20sui%20principi,traduzione%20di%20questi%20principi%20in">[13]</a>. Nella pratica bancaria ci√≤ si traduce, ad esempio, nel prevedere che le decisioni pi√π impattanti (es. rifiuto di credito, segnalazione di operazione sospetta) siano riesaminate o avallate da personale competente, e che gli operatori addetti abbiano <em>formazione adeguata sull&#39;IA</em> e potere di fermare o correggere il sistema<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=affidata%20la%20sorveglianza%20umana%20dispongano,quale%20%C3%A8%20stata%20affidata%20la">[14]</a>. </p>
<p>I grandi istituti si stanno infatti orientando verso modelli &quot;ibridi&quot; in cui l&#39;IA elabora raccomandazioni ma l&#39;uomo ha l&#39;ultima parola, investendo in programmi di <strong>upskilling</strong> del personale per colmare il gap di competenze tecniche<a href="https://www.eba.europa.eu/publications-and-media/publications/special-topic-artificial-intelligence#:~:text=GPAI%20could%20present%20challenges,the%20required%20skills%20and%20talent">[16]</a>. Ci√≤ risponde anche a esigenze di gestione del rischio: come osservato dall&#39;EBA, molte banche adottano un approccio graduale e prudente all&#39;AI, introducendo solide <strong>misure di controllo e &quot;guardrails&quot;</strong> prima di estendere l&#39;uso di modelli avanzati, specie di tipo generativo, e testando i casi d&#39;uso pi√π rischiosi solo dopo aver maturato sufficiente esperienza e confidenza nella tecnologia<a href="https://www.eba.europa.eu/publications-and-media/publications/special-topic-artificial-intelligence#:~:text=challenges%20in%20consumer%20experiences">[17]</a>.</p>
<p>Dal punto di vista strettamente normativo, emergono <em>nuovi obblighi operativi</em>: ad esempio requisiti di <strong>trasparenza verso gli utenti</strong>. Il regolamento AI Act impone (anche per sistemi non high-risk) che chi interagisce con un&#39;IA sia informato del fatto che sta interagendo con una macchina e non un essere umano<a href="https://www.consilium.europa.eu/en/press/press-releases/2023/12/09/artificial-intelligence-act-council-and-parliament-strike-a-deal-on-the-first-worldwide-rules-for-ai/#:~:text=provisional%20agreement%20also%20provides%20for,exposed%20to%20such%20a%20system">[18]</a>. Ci√≤ significa che in un contact center automatizzato o chatbot bancario dev&#39;essere chiaramente segnalato al cliente che il servizio √® erogato da un sistema AI, e occorre prevedere canali di <em>escalation a un operatore umano</em> su richiesta.</p>
<p>Analogamente, se lo strumento di GenAI (Generative Artificial Intelligence) genera contenuti (es. una risposta testuale in linguaggio naturale al cliente), vanno forniti eventuali disclaimer sull&#39;origine automatica e accuratezza delle informazioni. Sul fronte <strong>non-discriminazione e fairness</strong>, sebbene la normativa bancaria italiana contenga solo generiche clausole di equit√† nell&#39;erogazione del credito, il nuovo quadro richiede una grande attenzione: l&#39;AI Act inserisce esplicitamente il divieto di algoritmi che introducano classificazioni basate su caratteristiche sensibili (pratiche assimilabili al <em>social scoring</em> sono vietate) e, come detto, include il credito tra i casi ad alto rischio proprio per i possibili <em>bias algoritmici</em><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=utilizzati%20per%20valutare%20il%20merito,previsti%20dal%20diritto%20dell%27Unione%20al">[1]</a>. I garanti privacy e le autorit√† di consumo potranno sindacare pratiche scorrette se un modello nega sistematicamente servizi a categorie protette. </p>
<p>Pertanto, le banche devono implementare tecniche di <strong>AI governance</strong>: test proattivi dei modelli per rilevare disparit√† di trattamento (bias audit), documentazione trasparente delle variabili usate (feature importance), e meccanismi di reclamo efficaci per gli interessati. Un cliente ha diritto di sapere se una decisione sul suo finanziamento √® stata influenzata da un algoritmo e su quali parametri<a href="https://paradigma.it/2025/10/21/ai-concessione-credito-responsabilita/#:~:text=Un%20altro%20punto%20critico%20riguarda,possibilit%C3%A0%20di%20contestare%20eventuali%20errori">[19]</a>, nonch√© di ottenere intervento umano e contestare la decisione automatizzata - come previsto dal <a href="https://www.privacy-regulation.eu/it/22.htm">GDPR art.22</a>.</p>
<h3 id="principali-ambiguit-normative">Principali ambiguit√† normative</h3>
<p>Nonostante i progressi regolamentari, permangono aree grigie e nodi interpretativi. Un primo elemento di incertezza riguarda la <em>portata esatta delle categorie di alto rischio</em>: alcuni use case bancari non rientrano in modo netto nell&#39;Allegato III. </p>
<p>Ad esempio, l&#39;utilizzo di IA per <strong>Anti-Money Laundering</strong> (rilevazione di operazioni sospette) non √® elencato tra gli high-risk a meno che avvenga direttamente da autorit√† di contrasto. Infatti il regolamento europeo chiarisce che i sistemi di IA usati in procedimenti amministrativi da autorit√† fiscali e doganali, e dalle Unita‚Äô di Informazione Finanziaria (FIU) per analisi antiriciclaggio, non vanno trattati come sistemi di IA ad alto rischio impiegati dalle forze dell‚Äôordine. Resta pero‚Äô fermo che l‚Äôuso dell‚ÄôIA non deve creare disuguaglianze o ostacolare il diritto alla difesa, soprattutto quando le decisioni sono difficili da contestare per mancanza di trasparenza.<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=di%20IA%20specificamente%20destinati%20a%C2%A0essere,L%27impatto%20dell%27utilizzo">[20]</a>. </p>
<p>Questo solleva dubbi: un algoritmo che <em>blocca preventivamente</em> transazioni o conti correnti potrebbe incidere su diritti fondamentali (es. libert√† economica) quasi quanto un sistema di credit scoring, ma formalmente l&#39;AI Act non lo copre come high-risk. La scelta sembra motivata dal voler favorire l&#39;innovazione anti-frode, ma resta ambigua la linea di confine: le banche dovranno decidere se trattare questi sistemi &quot;non classificati&quot; comunque con un approccio conservativo (applicando volontariamente requisiti affini a quelli high-risk) per prudenza e accountability.</p>
<p>Ulteriore ambiguit√† concerne la <strong>definizione di &quot;rischio significativo&quot;</strong> nell&#39;AI Act. </p>
<p>La norma prevede infatti che i sistemi elencati in Allegato III <em>non</em> siano considerati ad alto rischio se, &quot;in deroga&quot;, <em>non presentano un rischio significativo</em> per salute, sicurezza o diritti<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=considerati%20ad%20alto%20rischio%20anche,%20risultato%20del%20processo%20decisionale">[21]</a>. Questa clausola di esenzione √® di non facile applicazione pratica: ad esempio, una piccola soluzione AI usata in via sperimentale su pochi clienti, pur tecnicamente rientrando in una categoria (mettiamo credit scoring), potrebbe essere sostenuta come a rischio trascurabile dal fornitore; tuttavia i criteri per stabilirlo non sono esplicitati e c&#39;√® il rischio di interpretazioni difformi. Le aziende potrebbero essere restie a &quot;declassare&quot; un sistema da high-risk a non, temendo contestazioni a posteriori. Si profila quindi un atteggiamento prudenziale, ma la mancanza di linee guida attuative al riguardo √® un gap che richieder√† chiarimenti (la Commissione √® delegata a emettere atti per modificare l&#39;Allegato III e fornire criteri, ma occorrer√† vedere come verr√† gestito).</p>
<p>Un terzo profilo di incertezza riguarda la <strong>metodologia e governance della FRIA</strong>. Trattandosi di un adempimento nuovo, non esistono ancora standard consolidati su <em>come condurre una valutazione di impatto etico/fondamentale</em>. L&#39;AI Act prevede che l&#39;<em>AI Office</em> (nuovo organismo europeo) fornisca un modello di questionario anche via tool automatizzato per facilitare i deployer<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=L'ufficio%20per%20l'IA%20elabora%20un%20modello%20di%20questionario,%20a%20norma%20del%20presente%20articolo%20in%20modo%20semplificato.">[22]</a>, ma fino a che ci√≤ non sar√† sviluppato, le imprese dovranno arrangiarsi ispirandosi a linee guida analoghe (es. quelle del Garante per valutazioni etiche, o framework come l&#39;Assessment List for Trustworthy AI dell&#39;UE). </p>
<blockquote>
<p>Quali competenze dovranno coinvolgere? Chi sar√† l&#39;&quot;autorit√† di notifica&quot; della FRIA in Italia per il settore bancario - il Ministero dello Sviluppo Economico, Banca d&#39;Italia o un nuovo organo?</p>
</blockquote>
<p>Tutto questo non √® ancora definito con precisione, e ci√≤ crea ambiguit√† operative. </p>
<p>Ambiguit√† anche nella <strong>distinzione di ruoli e responsabilit√†</strong> lungo la filiera AI. In molti casi le banche utilizzano soluzioni di IA fornite da vendor terzi o basate su modelli generativi pre-addestrati (es. un foundation model linguistico integrato nel chatbot). Il regolamento distingue <strong>&quot;fornitore&quot;</strong> (chi immette sul mercato il sistema AI) e <strong>&quot;utilizzatore (deployer)&quot;</strong> finale; nel caso bancario, per√≤, una banca che sviluppi internamente un algoritmo per uso proprio potrebbe essere considerata sia fornitore che deployer, con obblighi cumulativi (inclusa la conformit√† tecnica e marcatura CE del sistema high-risk). Se invece acquista un servizio AI esterno, dovr√† comunque garantire gli obblighi dei deployer (FRIA, registrazione nel database UE, sorveglianza d&#39;uso) ma dipende dal fornitore per la documentazione tecnica conforme. √à incerto come gestire contrattualmente questa condivisione di responsabilit√†: le banche dovranno pretendere dai vendor garanzie di conformit√† AI Act (es. <strong>EU Declaration of Conformity</strong> per sistemi high-risk) e accesso alle info sul modello per poter fare la FRIA.</p>
<p>Un&#39;altra area grigia √® la <strong>gestione della spiegabilit√† ed esercizio dei diritti GDPR</strong> in presenza di modelli AI opachi (es. deep learning). Il GDPR d√† all&#39;interessato diritto ad avere spiegazioni significative sulla logica di decisioni automatizzate; tuttavia, le tecniche di explainable AI sono ancora emergenti e potrebbe non essere possibile fornire spiegazioni semplici di modelli complessi. Le banche dovranno bilanciare questo obbligo con la tutela del segreto industriale sui propri algoritmi. Non esiste ancora un consenso su quale livello di trasparenza sia &quot;sufficiente&quot;, ambito in cui sono attesi orientamenti dal <a href="https://www.edpb.europa.eu/our-work-tools/our-documents/letters/edpb-reply-letter-ai-office-edpb-statement-role-data_en">EDPB o dal futuro AI Office</a>.</p>
<p>Infine, permane incertezza su <strong>come tradurre in prassi concrete i principi etici condivisi</strong>. La letteratura e le autorit√† convergono su principi come <em>non-discriminazione, trasparenza, oversight umano</em><a href="https://www.bancaditalia.it/pubblicazioni/qef/2022-0721/QEF_721_IT.pdf#:~:text=convergenza%20sui%20principi,traduzione%20di%20questi%20principi%20in">[13]</a>, ma, come notato da Banca d&#39;Italia, risulta meno agevole incorporarli in norme vincolanti e procedure operative efficaci<a href="https://www.bancaditalia.it/pubblicazioni/qef/2022-0721/QEF_721_IT.pdf#:~:text=convergenza%20internazionale,%20prassi%20concrete%22">[23]</a>. Ad esempio, tutti concordano sull&#39;evitare bias, ma definire metriche quantitative di fairness e soglie accettabili di disparit√† √® complesso e lasciato all&#39;autonomia delle imprese per ora. Similmente, √® pacifico che debba esserci un intervento umano, ma quanta discrezionalit√† e in quale fase del processo √® adeguato? Sono aspetti su cui si naviga ancora a vista, con approcci conservativi (ad es. richiedere sempre un doppio controllo umano indipendente per certe decisioni critiche) in attesa di prassi consolidate.</p>
<h3 id="implicazioni-operative-per-un-mvp">Implicazioni operative per un MVP</h3>
<p>Le evidenze sopra delineate informano direttamente i requisiti del prototipo di un possibile tool (i.e. &quot;AI Act Navigator&quot; o &quot;FRIA/DPIA Evidence Builder&quot;). </p>
<p>In sintesi, l&#39;MVP dovr√†: </p>
<ol>
<li>incorporare un sistema di <em>triage dei casi d&#39;uso</em> basato su domande mirate che consentano di identificare se un use case ricade in categorie di <em>alto rischio AI Act</em> o presenta trigger DPIA GDPR, guidando l&#39;utente (es. un Compliance officer) nelle classificazioni corrette. </li>
<li>Dovr√† implementare un insieme di <strong>regole decisionali</strong> (business rules) trasparenti: ad esempio, se l&#39;utente indica che il sistema AI effettua valutazione del merito creditizio di clienti retail, il wizard dovr√† automaticamente segnalarlo come <em>AI Act Allegato III - high-risk</em> e predisporre gli step successivi (es. elenco requisiti da soddisfare, obbligo FRIA, ecc.)<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=utilizzati%20per%20valutare%20il%20merito,previsti%20dal%20diritto%20dell%27Unione%20al">[1]</a>. Se il caso d&#39;uso comporta trattamento di categorie particolari di dati o profilazione estesa, il tool dovr√† suggerire obbligo di DPIA. </li>
<li>L&#39;output del wizard dovr√† includere un <em>cruscotto di evidenze e obblighi</em>: ad es. una checklist personalizzata con &quot;Documenti da predisporre&quot; (es. <em>Scheda descrittiva sistema AI</em>, <em>DPIA</em>, <em>FRIA</em>, <em>registro trattamento</em>, <em>contratto con fornitore</em>‚Ä¶), &quot;Requisiti applicabili&quot; (es. <em>art. 10 AI Act - data governance, art. 14 - oversight umano</em>‚Ä¶), &quot;Azioni consigliate&quot; (es. <em>valutare bias su dataset</em>, <em>previsto intervento umano prima decisione definitiva</em>, <em>informativa agli interessati da aggiornare</em>). </li>
<li>L&#39;MVP dovr√† integrare <strong>disclaimer e note esplicative</strong> in ogni sezione critica, per gestire le ambiguit√† normative: ad esempio una nota che chiarisca &quot;<em>Se il vostro caso non rientra esattamente nelle categorie AI Act ma presenta rischi potenziali, si consiglia l&#39;approccio pi√π prudente - vedere sezione &#39;Ambiguit√†&#39;</em>&quot;. Oppure, in caso di dubbio sulla necessit√† di DPIA: &quot;<em>In base alle informazioni fornite, non sussiste obbligo esplicito di DPIA ai sensi art.35 GDPR, ma si raccomanda comunque una valutazione documentata dato l&#39;uso esteso di dati personali (opzione conservativa)</em>&quot;. </li>
<li>Fondamentale sar√† la <strong>tracciabilit√† e giustificazione</strong> delle raccomandazioni: nella prossima sezione &quot;Evidence table&quot; verr√† fornito il razionale (fonte normativa) dietro ogni regola del wizard, aumentando la confidenza dell&#39;utente nelle indicazioni fornite. L&#39;MVP quindi non solo guider√† step-by-step (wizard) ma funger√† anche da <em>knowledge base</em> consultabile, con sezioni &quot;Perch√© ti chiediamo questo?&quot; o &quot;Perch√© √® richiesto questo documento?&quot; che attingono alle fonti autorevoli (Garante, EBA, normativa) raccolte nella ricerca<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=1,che%20comprende%20gli%20elementi%20seguenti">[6]</a>.</li>
</ol>
<h3 id="evidence-table">Evidence Table</h3>
<figure class="table-wrapper" data-enhanced-table><div class="table-wrapper__scroll"><table>
<thead>
<tr>
<th><strong>Tema</strong></th>
<th><strong>Evidenza</strong></th>
<th><strong>Fonte</strong></th>
<th><strong>Implicazione per wizard</strong></th>
<th><strong>Confidenza</strong></th>
</tr>
</thead>
<tbody><tr>
<td><strong>Use case bancari ad alto rischio (AI Act)</strong></td>
<td>L&#39;AI Act classifica come <em>alto rischio</em> i sistemi IA usati per valutare affidabilit√† creditizia di persone (credit scoring) e per impieghi in ambito occupazionale (es. selezione del personale). I sistemi di questo tipo possono infatti incidere significativamente su diritti e tenore di vita degli individui, rischiando di perpetuare discriminazioni<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=utilizzati%20per%20valutare%20il%20merito,previsti%20dal%20diritto%20dell%27Unione%20al">[1]</a>. Sono esclusi invece dall&#39;Allegato III i sistemi IA per rilevare frodi finanziarie o calcolo requisiti patrimoniali (non considerati ad alto rischio)<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=o%C2%A0sull%27orientamento%20sessuale%2C%20o%C2%A0possono%20dar%20vita,ad%20alto%20rischio%20ai%20sensi">[3]</a>.</td>
<td><em>Reg. UE 2024/1689 (AI Act)</em>, consid. 58 e 59<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=utilizzati%20per%20valutare%20il%20merito,previsti%20dal%20diritto%20dell%27Unione%20al">[1]</a>; <em>Paradigma, 2025</em><a href="https://paradigma.it/2025/10/21/ai-concessione-credito-responsabilita/#:~:text=clientela,economiche%20e%20sociali%20che%20comportano">[24]</a>.</td>
<td>Identificare subito se un use case rientra in categorie di Allegato III (es. credito, HR). In tal caso marcare come &quot;High-Risk AI Act&quot; e attivare i moduli di valutazione conformit√† (FRIA, requisiti art. 8-15 AI Act). Per ambiti esclusi (es. anti-frode) segnalare comunque obblighi settoriali ma con regime AI Act diverso.</td>
<td><strong>Alta</strong> (testo normativo chiaro; confermato da dottrina)</td>
</tr>
<tr>
<td><strong>DPIA - trigger nel settore bancario</strong></td>
<td>Il GDPR richiede la DPIA per trattamenti ad alto rischio; linee guida WP29/EDPB elencano criteri: tra essi profilazione o scoring su larga scala su situazione economica, decisioni automatizzate con effetti giuridici (es. concessione prestiti), monitoraggio sistematico, uso di dati sensibili o tecnologie nuove (come IA)<a href="https://www.latuaprivacy.com/site/approfondimenti/16-la-valutazione-d-impatto#:~:text=la%20concessione%20di%20un%20finanziamento">[25]</a>. Il Garante ha specificato 12 tipologie obbligatorie, includendo: <em>&quot;trattamenti valutativi o di scoring su larga scala&quot;</em> e <em>&quot;decisioni automatizzate che incidono significativamente sull&#39;interessato (es. screening clienti di una banca per concessione finanziamento)&quot;</em><a href="https://www.latuaprivacy.com/site/approfondimenti/16-la-valutazione-d-impatto#:~:text=la%20valutazione%20d'impatto:">[4]</a><a href="https://www.latuaprivacy.com/site/approfondimenti/16-la-valutazione-d-impatto#:~:text=la%20concessione%20di%20un%20finanziamento">[25]</a>.</td>
<td><em>Linee Guida WP29 n.248/2017</em> (EDPB); <em>Garante Privacy, Provv. 467/2018</em><a href="https://www.latuaprivacy.com/site/approfondimenti/16-la-valutazione-d-impatto#:~:text=la%20concessione%20di%20un%20finanziamento">[5]</a>.</td>
<td>Nel questionario wizard, domande per rilevare se il caso d&#39;uso coinvolge profilazione finanziaria, decisioni automatizzate su clienti, monitoraggio transazioni, uso di biometria, ecc. - in caso affermativo, far scattare alert &quot;DPIA obbligatoria&quot; e aggiungere il task &quot;Esegui DPIA&quot; nell&#39;output.</td>
<td><strong>Alta</strong> (linee guida ufficiali EDPB recepite dal Garante)</td>
</tr>
<tr>
<td><strong>FRIA - obbligo e contenuti</strong></td>
<td>L&#39;AI Act (art. 27) obbliga i <em>deployer</em> di sistemi IA ad alto rischio (p.a. e privati che forniscono servizi pubblici, nonch√© chi usa sistemi di Allegato III punti 5(b) e (c)) a effettuare una <strong>Valutazione d&#39;Impatto sui Diritti Fondamentali</strong> prima dell&#39;uso. La FRIA deve includere: descrizione del contesto d&#39;uso e scopo del sistema, durata e frequenza d&#39;uso, categorie di persone impattate, rischi specifici per diritti (tenendo conto info fornite dal provider ai sensi art.13 AI Act), misure di sorveglianza umana previste, e misure di mitigazione/gestione in caso di problemi (incl. meccanismi di reclamo)<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=una%20descrizione%20dei%20processi%20del,con%20la%20sua%20finalit%C3%A0%20prevista">[7]</a><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=Obblighi%20dei%20fornitori%20di%20modelli%20di%20IA%20per%20finalit%C3%A0%20generali%20con%20rischio%20sistemico,%20In%20aggiunta">[8]</a>. L&#39;esito va notificato all&#39;autorit√† di vigilanza di mercato, usando il modello che sar√† predisposto (anche via tool automatizzato dall&#39;AI Office). Se il deployer ha gi√† svolto una DPIA GDPR che copre parte degli aspetti, la FRIA pu√≤ integrare quella analisi senza duplicarla<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=d%27impatto%20sulla%20protezione%20dei%20dati">[10]</a>.</td>
<td><em>Reg. UE 2024/1689</em>, art. 27<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=che%20comprende%20gli%20elementi%20seguenti">[6]</a><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=una%20descrizione%20dei%20processi%20del,con%20la%20sua%20finalit%C3%A0%20prevista">[7]</a>; Consiglio UE, Comunicato 9/12/23<a href="https://www.consilium.europa.eu/en/press/press-releases/2023/12/09/artificial-intelligence-act-council-and-parliament-strike-a-deal-on-the-first-worldwide-rules-for-ai/#:~:text=The%20provisional%20agreement%20provides%20for,system%20to%20inform%20natural%20persons">[26]</a>.</td>
<td>Il wizard deve spiegare chiaramente quando √® richiesta la FRIA (es. &quot;Use case classificato High-Risk ‚Üí obbligatoria FRIA prima della messa in esercizio&quot;). Dovr√† guidare l&#39;utente nell&#39;assemblare gli elementi per la FRIA: es. chiedere di descrivere finalit√† e contesto, elenco interessati impattati, ecc., e produrre uno schema di report. Inoltre, deve ricordare la necessit√† di <em>notifica all&#39;autorit√†</em> e fornire eventualmente un template di output conforme (es. modulistica standard AI Office). Deve anche segnalare che se √® stata fatta una DPIA, questa va aggiornata/integrata piuttosto che duplicata.</td>
<td><strong>Alta</strong> (disposizione di legge dettagliata)</td>
</tr>
<tr>
<td><strong>Human oversight - obbligo e modelli</strong></td>
<td>Le normative settoriali e l&#39;AI Act convergono sull&#39;obbligo di mantenere <strong>supervisione umana efficace</strong> sui sistemi IA ad alto rischio. Art. 14 AI Act impone che tali sistemi siano progettati per essere &quot;sorvegliabili&quot; da persone, e che le persone deputate al controllo abbiano competenze, formazione e autorit√† per intervenire, anche interrompendo il sistema se necessario<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=affidata%20la%20sorveglianza%20umana%20dispongano,quale%20%C3%A8%20stata%20affidata%20la">[14]</a><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=necessarie%20nonch%C3%A9%20del%20sostegno%20necessario">[27]</a>. Le <strong>Linee Guida EBA</strong> sul credito prescrivono che l&#39;IA non operi in autonomia piena: l&#39;intermediario deve poter rivedere ed <em>eventualmente derogare</em> alle decisioni del modello (principio del <em>&quot;human-in-the-loop&quot;</em>)<a href="https://paradigma.it/2025/10/21/ai-concessione-credito-responsabilita/#:~:text=chiariscono%20che%20l%E2%80%99uso%20di%20modelli,%E2%80%9Cal%20posto%E2%80%9D%20del%20giudizio%20dell%E2%80%99intermediario">[12]</a>. Ad es., l&#39;art. 172(3) CRR gi√† richiede che nelle banche IRB vi sia possibilit√† di <em>override umano</em> dei risultati dei modelli interni di rating<a href="https://www.eba.europa.eu/sites/default/files/2025-11/2019d1b5-59f8-4149-ad3b-23cfcd4388a1/EBA%20Chair%20letter%20to%20Mr%20Berrigan%20and%20Mr%20Viola%20on%20outcome%20of%20EBA%E2%80%99s%20AI%20Act%20mapping%20exercise.pdf#:~:text=CRR%3A%20Article%20149,and%20personnel%20responsible%20for%20approving">[28]</a>. Dalle analisi EBA emerge che le banche UE stanno adottando approcci graduati dove l&#39;<strong>intervento umano</strong> √® garantito specie nelle fasi iniziali di adozione di IA avanzata, per controllare i rischi<a href="https://www.eba.europa.eu/publications-and-media/publications/special-topic-artificial-intelligence#:~:text=GPAI%20could%20present%20challenges,the%20required%20skills%20and%20talent">[16]</a><a href="https://www.eba.europa.eu/publications-and-media/publications/special-topic-artificial-intelligence#:~:text=In%20view%20of%20these%20potential,potential%20effects%20and%20necessary%20mitigants">[29]</a>.</td>
<td><em>AI Act</em>, art. 14<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=sorveglianza%20umana%20affinch%C3%A9%20prenda%20decisioni,significative%20per%20le%20persone%20in">[30]</a><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=Sorveglianza%20umana">[31]</a>; <em>EBA Risk Report 2024</em><a href="https://www.eba.europa.eu/publications-and-media/publications/special-topic-artificial-intelligence#:~:text=GPAI%20could%20present%20challenges,the%20required%20skills%20and%20talent">[16]</a><a href="https://www.eba.europa.eu/publications-and-media/publications/special-topic-artificial-intelligence#:~:text=challenges%20in%20consumer%20experiences">[17]</a>; <em>Paradigma 2025</em> (cit. EBA GL)<a href="https://paradigma.it/2025/10/21/ai-concessione-credito-responsabilita/#:~:text=chiariscono%20che%20l%E2%80%99uso%20di%20modelli,%E2%80%9Cal%20posto%E2%80%9D%20del%20giudizio%20dell%E2%80%99intermediario">[12]</a>.</td>
<td>Il wizard deve includere campi/domande per verificare la presenza di meccanismi di oversight: es. &quot;√à previsto un intervento umano prima che la decisione finale venga applicata al cliente?&quot;; &quot;Il personale addetto ha facolt√† di bloccare o correggere l&#39;output dell&#39;AI?&quot;. In base alle risposte, fornire alert se l&#39;oversight risulta inadeguata (trigger di non conformit√† art. 14). Inoltre, nelle <em>specifiche di output</em> per ogni use case, aggiungere raccomandazioni su modelli di controllo sostenibili (es. doppia verifica umana per decisioni critiche, training specifico per operatori AI, audit periodici dei risultati del modello).</td>
<td><strong>Alta</strong> (requisito legale + best practice EBA)</td>
</tr>
<tr>
<td><strong>Trasparenza verso individui</strong></td>
<td>L&#39;AI Act impone obblighi di trasparenza anche per sistemi non high-risk: ad esempio, chi utilizza un <strong>chatbot</strong> o sistema che interagisce con persone deve informare chiaramente l&#39;utente che si tratta di un sistema automatizzato<a href="https://www.consilium.europa.eu/en/press/press-releases/2023/12/09/artificial-intelligence-act-council-and-parliament-strike-a-deal-on-the-first-worldwide-rules-for-ai/#:~:text=provisional%20agreement%20also%20provides%20for,exposed%20to%20such%20a%20system">[18]</a>. Inoltre, se un contenuto (testo, immagine) √® generato da IA, occorre dichiararlo all&#39;utente finale (per prevenire inganni). In ambito bancario, il GDPR art.13-14 e 22 gi√† richiedono di comunicare agli interessati l&#39;esistenza di decisioni automatizzate e fornire informazioni significative sulla logica usata e sulle conseguenze previste<a href="https://paradigma.it/2025/10/21/ai-concessione-credito-responsabilita/#:~:text=Un%20altro%20punto%20critico%20riguarda,possibilit%C3%A0%20di%20contestare%20eventuali%20errori">[19]</a>. La normativa nazionale (es. TUB art. 124-bis) ribadisce che se la concessione di credito avviene con strumenti automatizzati, il cliente va informato in modo chiaro e ha diritto a spiegazioni adeguate.</td>
<td><em>AI Act</em>, art. 52 (ora 50)<a href="https://www.consilium.europa.eu/en/press/press-releases/2023/12/09/artificial-intelligence-act-council-and-parliament-strike-a-deal-on-the-first-worldwide-rules-for-ai/#:~:text=provisional%20agreement%20also%20provides%20for,exposed%20to%20such%20a%20system">[18]</a>; <em>GDPR</em>, art. 13-14, 22; <em>Paradigma 2025</em><a href="https://paradigma.it/2025/10/21/ai-concessione-credito-responsabilita/#:~:text=Un%20altro%20punto%20critico%20riguarda,possibilit%C3%A0%20di%20contestare%20eventuali%20errori">[19]</a>.</td>
<td>Il wizard deve chiedere se l&#39;AI interagisce con clienti o determina output rivolti a persone. In caso affermativo, indicare tra gli output obbligatori: &quot;Preparare un&#39;informativa specifica per gli utenti&quot;, &quot;Inserire disclaimer visibili nell&#39;interfaccia (es. &#39;Assistente virtuale automatizzato&#39;)&quot;. Inoltre, fornire linee guida su come redigere spiegazioni delle decisioni in linguaggio comprensibile. Il tool potrebbe includere un modulo di <strong>template di informativa</strong> da riempire con i dettagli del caso d&#39;uso (es. tipo di logica algoritmica, dati usati) in conformit√† a GDPR.</td>
<td><strong>Alta</strong> (norme chiare GDPR + AI Act)</td>
</tr>
<tr>
<td><strong>Non discriminazione e fairness</strong></td>
<td>Il principio di non discriminazione non √® dettagliatamente regolato nelle norme finanziarie, ma √® un focus centrale dell&#39;AI Act e delle autorit√†. La Banca d&#39;Italia nota che nelle disposizioni di trasparenza bancaria vi sono scarsi riferimenti espliciti alla <em>parit√† di trattamento</em>, e l&#39;uso di tecniche AI-ML sollecita nuove attenzioni su questo fronte<a href="https://www.bancaditalia.it/pubblicazioni/qef/2022-0721/QEF_721_IT.pdf#:~:text=%EF%82%B7%20%E2%80%9Cla%20non%20discriminazione%20nei,concessione%20del%20credito%20riceve%20nuove">[32]</a>. L&#39;AI Act vieta sistemi di scoring sociale e categorizzazione in base a dati sensibili, e nei considerando evidenzia il rischio che modelli di credito o di recruiting possano <em>perpetuare bias storici</em> (ad es. sfavorire donne, minoranze)<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=l%27accesso%20di%20tali%20persone%20alle,previsti%20dal%20diritto%20dell%27Unione%20al">[33]</a>. Casi reali confermano il pericolo: algoritmi di HR troppo opachi o di credito basati su dati correlati a etnia/zona possono produrre disparit√†. Il Garante privacy italiano ha richiamato come la profilazione creditizia debba evitare di trattare dati sensibili o proxy di quelli (es. cap di residenza) senza adeguate cautele<a href="https://paradigma.it/2025/10/21/ai-concessione-credito-responsabilita/#:~:text=A%20questo%20si%20aggiunge%20il,presidi%20tecnici%20e%20giuridici%20solidi">[34]</a>.</td>
<td><em>Banca d&#39;Italia QEF 721/2022</em><a href="https://www.bancaditalia.it/pubblicazioni/qef/2022-0721/QEF_721_IT.pdf#:~:text=%EF%82%B7%20%E2%80%9Cla%20non%20discriminazione%20nei,concessione%20del%20credito%20riceve%20nuove">[32]</a>; <em>AI Act</em> consid. 58<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=l%27accesso%20di%20tali%20persone%20alle,previsti%20dal%20diritto%20dell%27Unione%20al">[33]</a>; <em>Paradigma 2025</em><a href="https://paradigma.it/2025/10/21/ai-concessione-credito-responsabilita/#:~:text=classifica%20i%20sistemi%20di%20intelligenza,economiche%20e%20sociali%20che%20comportano">[35]</a>.</td>
<td>Il wizard deve includere checkpoint dedicati alla fairness: es. chiedere se il dataset √® stato controllato per bias (squilibri rappresentativi), se il modello utilizza attributi potenzialmente discriminanti (diretti o indiretti). In output, per casi d&#39;uso sensibili (credito, HR), raccomandare di effettuare un <em>&quot;bias audit&quot;</em> e documentare gli esiti nella FRIA. Inoltre, segnalare l&#39;opzione conservativa di escludere dal modello variabili non pertinenti o potenzialmente proxy di categorie protette. Fornire riferimenti a linee guida (es. Appendice tecnica su metriche di fairness) nella bibliografia del wizard per approfondimento.</td>
<td><strong>Media</strong> (principio generale chiaro, ma mancano metriche univoche)</td>
</tr>
<tr>
<td><strong>Overlap normativo e approcci conservativi</strong></td>
<td>L&#39;EBA ha riscontrato che molte esigenze dell&#39;AI Act (es. data governance, robustezza, oversight) sono in parte coperte dalle norme finanziarie esistenti, sebbene non vi siano <em>deroghe esplicite</em> nell&#39;AI Act per il settore bancario<a href="https://www.eba.europa.eu/sites/default/files/2025-11/2019d1b5-59f8-4149-ad3b-23cfcd4388a1/EBA%20Chair%20letter%20to%20Mr%20Berrigan%20and%20Mr%20Viola%20on%20outcome%20of%20EBA%E2%80%99s%20AI%20Act%20mapping%20exercise.pdf#:~:text=includes%20a%20wide%20range%20of">[36]</a>. Ci√≤ significa che banche e intermediari dovranno rispettare entrambe le cornici: ad es., un modello di credito IRB deve seguire le regole CRR/EBA <em>e</em> soddisfare i requisiti AI Act (documentazione tecnica, testing, ecc.). Questo doppio binario pu√≤ creare oneri, ma anche opportunit√† di integrazione. Ad esempio, i controlli periodici sui modelli richiesti da Banca d&#39;Italia/EBA (validazioni, backtesting) possono valere anche come misure di monitoraggio continuo ai sensi AI Act. Nel dubbio interpretativo su categorie borderline, le banche stanno adottando un approccio prudenziale, spesso applicando volontariamente le misure pi√π rigorose. Una prassi raccomandata √® considerare la <strong>FRIA e DPIA combinate</strong> come parte di un unico processo di <em>AI risk assessment</em>, coinvolgendo funzioni diverse (Compliance, DPO, Risk Management) per coprire tutti gli aspetti.</td>
<td><em>EBA Chair Letter 2025</em><a href="https://www.eba.europa.eu/sites/default/files/2025-11/2019d1b5-59f8-4149-ad3b-23cfcd4388a1/EBA%20Chair%20letter%20to%20Mr%20Berrigan%20and%20Mr%20Viola%20on%20outcome%20of%20EBA%E2%80%99s%20AI%20Act%20mapping%20exercise.pdf#:~:text=includes%20a%20wide%20range%20of">[36]</a>; <em>Banca d&#39;Italia QEF</em><a href="https://www.bancaditalia.it/pubblicazioni/qef/2022-0721/QEF_721_IT.pdf#:~:text=regolamentazione%20specifica%20sugli%20stessi,nelle%20disposizioni%20di%20trasparenza%20sono">[37]</a><a href="https://www.bancaditalia.it/pubblicazioni/qef/2022-0721/QEF_721_IT.pdf#:~:text=%EF%82%B7%20%E2%80%9Cconvergenza%20internazionale%20sui%20principi,traduzione%20di%20questi%20principi%20in">[13]</a>.</td>
<td>Il wizard dovrebbe fornire all&#39;utente un quadro di <em>&quot;intersezione normativa&quot;</em> - ad esempio una sezione riassuntiva che dica: &quot;Il tuo caso richiede: conformit√† AI Act (requisiti X, Y, Z) <strong>e anche</strong> rispetto delle regole bancarie ABC (es. Linee guida EBA x)&quot;. Suggerire un approccio integrato: output potrebbe consigliare di unificare DPIA+FRIA in un unico documento/procedura aziendale. Inoltre, nelle spiegazioni, il tool evidenzier√† dove gli obblighi coincidono (es. qualit√† dati √® sia requisito AI Act art.10 che buona pratica modelli interni) per evitare duplicazioni. In caso di incertezza (use case non esplicitamente normato), il wizard adotter√† il flag &quot;approccio conservativo suggerito&quot; e includer√† misure extra precauzionali.</td>
<td><strong>Alta</strong> (ricognizione EBA autorevole; convergenza con prassi Banca d&#39;Italia)</td>
</tr>
</tbody></table>
</div></figure><h2 id="questioni-residue-aperte">Questioni Residue Aperte</h2>
<p>Rimangono aperti alcuni apunti, come: </p>
<ul>
<li><strong>Criteri pratici per &quot;rischio significativo&quot; (Art.6(3) AI Act):</strong> non √® chiaro come un fornitore o utilizzatore potr√† dimostrare che un sistema rientrante in Allegato III <strong>non</strong> presenta un <em>rischio significativo</em> e quindi esentarlo dal regime high-risk<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=considerati%20ad%20alto%20rischio%20anche,%20risultato%20del%20processo%20decisionale">[21]</a>. Serviranno linee guida su metriche di rischio e chi avalla tale auto-valutazione, per evitare decisioni e under-classification.</li>
<li><strong>Coordinamento tra Autorit√† (AI Act vs privacy vs settore):</strong> chi sar√† in pratica l&#39;autorit√† di riferimento per vigilare sui sistemi AI bancari? Il <em>Market Surveillance Authority</em> per high-risk AI potrebbe essere Banca d&#39;Italia (vigilanza bancaria) o un nuovo soggetto; il Garante Privacy manterr√† ruolo su DPIA e data protection; l&#39;EBA/ECB avranno voce tramite l&#39;<em>AI Board</em>. Occorrono protocolli chiari per prevenire conflitti o vuoti di competenza nelle valutazioni ex ante (FRIA) e nei controlli ex post.</li>
<li><strong>Standard di riferimento e certificazioni:</strong> dato il forte carattere tecnico dei requisiti AI Act, ci si chiede quali standard tecnici adotteranno le banche per dimostrare conformit√† (es. ISO 42001 AI Management? certificazioni di bias/fairness?). L&#39;EBA nota che Commissione emaner√† linee guida per la classificazione high-risk entro il 2 Feb 2026<a href="https://www.eba.europa.eu/sites/default/files/2025-11/d8b999ce-a1d9-4964-9606-971bbc2aaf89/AI%20Act%20implications%20for%20the%20EU%20banking%20sector.pdf">[65]</a>, ma sul piano operativo le banche vorrebbero un framework unificato. La domanda aperta: <em>conviene attendere standard ufficiali o partire con certificazioni volontarie (es. audit etici, attestazioni da terze parti) per stare avanti?</em></li>
<li><strong>Integrazione DPIA-FRIA:</strong> come implementare praticamente un processo unico che copra entrambe? Si deve produrre due report separati (uno per Garante, uno per autorit√† AI Act) o un unico <em>&quot;AI Risk Assessment Report&quot;</em> baster√† per entrambi scopi? E in caso di valutazione d&#39;impatto con esito dubbio (con un rischio residuo alto): per GDPR c&#39;√® un obbligo di consultazione del Garante, per AI Act non √® prevista ma magari l&#39;Autorit√† mercato pu√≤ intervenire; bisognerebbe capire come allineare queste escalation.</li>
<li><strong>Gestione dei fornitori terzi e liability:</strong> se un vendor fornisce un sistema AI non conforme e la banca subisce una violazione (es. multa per discriminazione), su chi ricade la responsabilit√†? Il regime AI Act prevede responsabilit√† primaria del <em>provider</em> per requisiti tecnici e dell&#39; utente (<em>user</em>) per uso improprio. Ma nei contratti reali tra banca e vendor serviranno clausole robuste su garanzie, indennizzi e accesso alle informazioni (audit). La questione aperta: le banche potranno chiedere contrattualmente ai vendor di condurre e condividere una FRIA da <em>provider</em>? Oppure ogni banca dovr√† farla in solitudine anche per pacchetti standard?</li>
<li><strong>Metriche di fairness e soglie accettabili:</strong> i regolatori richiederanno alle banche di quantificare e mantenere certi livelli di fairness nei modelli (es. <em>&quot;disparate impact ratio&quot;</em> non peggiore di 80%)? O rimarr√† tutto qualitativo? L&#39;assenza di criteri quantitativi univoci √® un problema: una banca potrebbe considerare accettabile un leggero scostamento, un&#39;altra no. Ci si chiede se l&#39;EBA o l&#39;AI Office elaboreranno guidance in tal senso.</li>
<li><strong>Uso di dati sensibili per finalit√† etiche (bias correction):</strong> paradosso noto - per testare se un modello √® discriminante servirebbe a volte considerare la variabile protetta (es. genere) nei dati; ma ci√≤ √® vietato per decisione. Il Garante permetter√† di usare dati sensibili simulati o raccolti post-assunzione per validare fairness? Su questo c&#39;√® incertezza e le banche faticano a definire metodologie di bias audit rispettose del GDPR.</li>
<li><strong>Interoperabilit√† con regolamenti futuri (ESG, AI liability):</strong> come si combineranno i requisiti dell&#39;AI Act con altri emergenti, ad esempio le iniziative sull&#39;<em>AI liability</em> (responsabilit√† civile per danni da AI) o la normativa ESG (che potrebbe includere uso etico di AI)? Le banche dovranno mappare anche questi aspetti. Inoltre rimane come domanda aperta se la documentazione predisposta (es. registro eventi AI, log decisioni) potr√† essere usata contro la banca in cause civili (un tema di liability non risolto: troppa trasparenza potrebbe esporre a contenziosi).</li>
<li><strong>Ruolo dell&#39;AI Office UE vs Autorit√† nazionali:</strong> l&#39;AI Office avr√† poteri di supervisione soprattutto sui foundation models e sui sistemi AI ad alto rischio con impatto. Ma potr√† emanare linee guida vincolanti anche per settori regolati? Le banche dovranno tenere un occhio a possibili indicazioni sovranazionali aggiuntive. La questione: se l&#39;AI Office (Commissione) identifica un modello bancario come <em>&quot;alto impatto&quot;</em> GPAI, potrebbe intervenire direttamente? Va chiarito.</li>
<li><strong>Aggiornamento continuo del tool vs evoluzione norme:</strong> riconoscendo che le interpretazioni e prassi attorno ad AI Act e DPIA evolveranno (giurisprudenza, orientamenti EDPB, nuove modifiche regolamentari), come mantenere il Navigator sempre aggiornato? Il processo di desk research ha limiti, alcune questioni saranno risolte solo con <em>regulatory feedback loop</em> (es. prime FRIA effettivamente svolte, sanzioni inflitte, ecc.). √à aperto il tema di governance del tool: chi in azienda (o consorzio ABI Lab) lo aggiorner√† con le <em>lessons learned</em> e nuove fonti normative man mano che emergono? Questo determina la sostenibilit√† a lungo termine della soluzione che √® stata proposta.</li>
</ul>
<h1 id="bibliografia">Bibliografia</h1>
<ul>
<li><strong>Regolamento (UE) 2024/1689 &quot;AI Act&quot;</strong> - Testo normativo fondamentale adottato nel giugno 2024<a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=utilizzati%20per%20valutare%20il%20merito,previsti%20dal%20diritto%20dell%27Unione%20al">[1]</a><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=i%20sistemi%20di%20IA%20destinati,o%C2%A0filtrare%20le%20candidature%20e%C2%A0valutare%20i%C2%A0candidati">[2]</a><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=i%20sistemi%20di%20IA%20previsti,ad%20alto%20rischio%20ai%20sensi">[3]</a><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=1,che%20comprende%20gli%20elementi%20seguenti">[6]</a><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=una%20descrizione%20dei%20processi%20del,con%20la%20sua%20finalit%C3%A0%20prevista">[7]</a><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=Obblighi%20dei%20fornitori%20di%20modelli%20di%20IA%20per%20finalit%C3%A0%20generali%20con%20rischio%20sistemico,%20In%20aggiunta">[8]</a><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=obbligo%20di%20notifica">[9]</a><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=d%27impatto%20sulla%20protezione%20dei%20dati">[10]</a><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=affidata%20la%20sorveglianza%20umana%20dispongano,quale%20%C3%A8%20stata%20affidata%20la">[14]</a><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=di%20IA%20specificamente%20destinati%20a%C2%A0essere,L%27impatto%20dell%27utilizzo">[20]</a><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=considerati%20ad%20alto%20rischio%20anche,%20risultato%20del%20processo%20decisionale">[21]</a><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=L'ufficio%20per%20l'IA%20elabora%20un%20modello%20di%20questionario,%20a%20norma%20del%20presente%20articolo%20in%20modo%20semplificato.">[22]</a><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=necessarie%20nonch%C3%A9%20del%20sostegno%20necessario">[27]</a><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=sorveglianza%20umana%20affinch%C3%A9%20prenda%20decisioni,significative%20per%20le%20persone%20in">[30]</a><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=Sorveglianza%20umana">[31]</a><a href="https://eur-lex.europa.eu/legal-content/IT/TXT/?uri=CELEX:32024R1689#:~:text=l%27accesso%20di%20tali%20persone%20alle,previsti%20dal%20diritto%20dell%27Unione%20al">[33]</a>. Definisce il quadro regolatorio UE per l&#39;IA con approccio basato sul rischio. <em>Rilevanza:</em> Allegati e articoli citati identificano i casi bancari high-risk (credito, HR) e impongono obblighi (es. art. 14 oversight umano, art. 27 FRIA). Base per molte compliance action del Navigator.</li>
<li><strong>DPIA: Garante Privacy (Provv. n. 467/2018) e Linee Guida WP29/EDPB WP248</strong> - Sintesi dei casi di trattamento obbligatoriamente soggetti a DPIA e dei criteri di rischio elevato<a href="https://www.latuaprivacy.com/site/approfondimenti/16-la-valutazione-d-impatto#:~:text=la%20valutazione%20d'impatto:">[4]</a><a href="https://www.latuaprivacy.com/site/approfondimenti/16-la-valutazione-d-impatto#:~:text=la%20concessione%20di%20un%20finanziamento">[5]</a><a href="https://www.latuaprivacy.com/site/approfondimenti/16-la-valutazione-d-impatto#:~:text=la%20concessione%20di%20un%20finanziamento">[25]</a>. <em>Rilevanza:</em> riferimento operativo per capire quando scatta la DPIA e quali elementi includere.</li>
<li><strong>Paradigma.it - &quot;AI e concessione del credito: tra innovazione e responsabilit√†&quot; (Ott 2025)</strong><a href="https://paradigma.it/2025/10/21/ai-concessione-credito-responsabilita/#:~:text=Le%20Linee%20Guida%20EBA%20del,supervisione%20costante">[11]</a><a href="https://paradigma.it/2025/10/21/ai-concessione-credito-responsabilita/#:~:text=La%20Banca%20d'Italia,%E2%80%9Cal%20posto%E2%80%9D%20del%20giudizio%20dell%E2%80%99intermediario">[12]</a><a href="https://paradigma.it/2025/10/21/ai-concessione-credito-responsabilita/#:~:text=Un%20altro%20punto%20critico%20riguarda,possibilit%C3%A0%20di%20contestare%20eventuali%20errori">[19]</a><a href="https://paradigma.it/2025/10/21/ai-concessione-credito-responsabilita/#:~:text=clientela,economiche%20e%20sociali%20che%20comportano">[24]</a><a href="https://paradigma.it/2025/10/21/ai-concessione-credito-responsabilita/#:~:text=A%20questo%20si%20aggiunge%20il,presidi%20tecnici%20e%20giuridici%20solidi">[34]</a><a href="https://paradigma.it/2025/10/21/ai-concessione-credito-responsabilita/#:~:text=classifica%20i%20sistemi%20di%20intelligenza,economiche%20e%20sociali%20che%20comportano">[35]</a> - Approfondimento giuridico italiano su obblighi e responsabilit√† nelle decisioni di credito. <em>Rilevanza:</em> utile per inquadrare prassi di controllo umano e accountability.</li>
<li><strong>Banca d&#39;Italia - Quaderno Economia e Finanza n.721 &quot;Intelligenza artificiale nel credit scoring&quot; (2022)</strong><a href="https://www.bancaditalia.it/pubblicazioni/qef/2022-0721/QEF_721_IT.pdf#:~:text=convergenza%20sui%20principi,traduzione%20di%20questi%20principi%20in">[13]</a><a href="https://www.bancaditalia.it/pubblicazioni/qef/2022-0721/QEF_721_IT.pdf#:~:text=convergenza%20internazionale,%20prassi%20concrete%22">[23]</a><a href="https://www.bancaditalia.it/pubblicazioni/qef/2022-0721/QEF_721_IT.pdf#:~:text=%EF%82%B7%20%E2%80%9Cla%20non%20discriminazione%20nei,concessione%20del%20credito%20riceve%20nuove">[32]</a><a href="https://www.bancaditalia.it/pubblicazioni/qef/2022-0721/QEF_721_IT.pdf#:~:text=regolamentazione%20specifica%20sugli%20stessi,nelle%20disposizioni%20di%20trasparenza%20sono">[37]</a> - Studio empirico e regolatorio su benefici/rischi e governance AI nel credito. <em>Rilevanza:</em> evidenzia la necessit√† di presidiare fairness e trasparenza con misure operative.</li>
<li><strong>EBA Risk Assessment Report, &quot;Special topic AI&quot; (Nov 2024)</strong><a href="https://www.eba.europa.eu/publications-and-media/publications/special-topic-artificial-intelligence#:~:text=GPAI%20could%20present%20challenges,the%20required%20skills%20and%20talent">[16]</a><a href="https://www.eba.europa.eu/publications-and-media/publications/special-topic-artificial-intelligence#:~:text=challenges%20in%20consumer%20experiences">[17]</a><a href="https://www.eba.europa.eu/publications-and-media/publications/special-topic-artificial-intelligence#:~:text=In%20view%20of%20these%20potential,potential%20effects%20and%20necessary%20mitigants">[29]</a> - Rapporto EBA su diffusione AI e sfide operative nelle banche. <em>Rilevanza:</em> supporta le sezioni su use case e skill gap.</li>
<li><strong>Comunicato Consiglio UE 9 Dec 2023 (Accordo AI Act)</strong> - Nota stampa del Consiglio che sintetizza obblighi chiave e requisiti di trasparenza<a href="https://www.consilium.europa.eu/en/press/press-releases/2023/12/09/artificial-intelligence-act-council-and-parliament-strike-a-deal-on-the-first-worldwide-rules-for-ai/#:~:text=provisional%20agreement%20also%20provides%20for,exposed%20to%20such%20a%20system">[18]</a><a href="https://www.consilium.europa.eu/en/press/press-releases/2023/12/09/artificial-intelligence-act-council-and-parliament-strike-a-deal-on-the-first-worldwide-rules-for-ai/#:~:text=The%20provisional%20agreement%20provides%20for,system%20to%20inform%20natural%20persons">[26]</a>.</li>
<li><strong>Lettera EBA Chair Jos√© M. Campa (Nov 2025) - Mapping AI Act vs regolamentazione bancaria</strong><a href="https://www.eba.europa.eu/sites/default/files/2025-11/2019d1b5-59f8-4149-ad3b-23cfcd4388a1/EBA%20Chair%20letter%20to%20Mr%20Berrigan%20and%20Mr%20Viola%20on%20outcome%20of%20EBA%E2%80%99s%20AI%20Act%20mapping%20exercise.pdf#:~:text=CRR%3A%20Article%20149,and%20personnel%20responsible%20for%20approving">[28]</a><a href="https://www.eba.europa.eu/sites/default/files/2025-11/2019d1b5-59f8-4149-ad3b-23cfcd4388a1/EBA%20Chair%20letter%20to%20Mr%20Berrigan%20and%20Mr%20Viola%20on%20outcome%20of%20EBA%E2%80%99s%20AI%20Act%20mapping%20exercise.pdf#:~:text=includes%20a%20wide%20range%20of">[36]</a> - Documento indirizzato alla Commissione che esamina sovrapposizioni tra obblighi AI Act e normativa bancaria. <em>Rilevanza:</em> utile per capire dove la compliance esistente copre requisiti AI Act.</li>
<li><strong>EBA Factsheet - &quot;AI Act: Implications for the EU banking sector&quot;</strong><a href="https://www.eba.europa.eu/sites/default/files/2025-11/d8b999ce-a1d9-4964-9606-971bbc2aaf89/AI%20Act%20implications%20for%20the%20EU%20banking%20sector.pdf">[65]</a> - Scheda EBA con tempistiche e primi orientamenti operativi sulla classificazione high-risk.</li>
</ul>
        </div>
      </section>
    </article>
  </main>
  <footer>
    <span data-it="¬© 2026 Mirko Calcaterra. Tutti i diritti riservati."
          data-en="¬© 2026 Mirko Calcaterra. All rights reserved.">
      ¬© 2026 Mirko Calcaterra. Tutti i diritti riservati.
    </span>
  </footer>
  <script>
    const BLOG_LANG_KEY = 'blogLang';
    const BLOG_THEME_KEY = 'blogTheme';
    const CURRENT_LANG = "it";
    const OTHER_LANG = "en";
    const OTHER_LANG_LINK = "../../../blog/en/ai-banking-dpia-ai-act/index.html";
    (function() {
      const body = document.body;
      const themeToggle = document.querySelector('.theme-toggle');
      const themeThumb = document.querySelector('.theme-toggle .theme-thumb');
      const langBtn = document.querySelector('.lang-btn');
      const tocElement = document.querySelector('.post-toc');
      const tocToggle = tocElement ? tocElement.querySelector('.post-toc__toggle') : null;
      const tocToggleText = tocElement ? tocElement.querySelector('.post-toc__toggle-text') : null;
      const tocTitle = tocElement ? tocElement.querySelector('.post-toc__title') : null;
      const tocLinks = tocElement ? Array.from(tocElement.querySelectorAll('.post-toc__link')) : [];
      const headingEntries = tocLinks
        .map((link) => {
          const id = link.getAttribute('href').slice(1);
          const target = document.getElementById(id);
          return target ? { link, target } : null;
        })
        .filter(Boolean);
      const tocLabels = CURRENT_LANG === 'it'
        ? { title: 'Indice', show: 'Mostra indice', hide: 'Nascondi indice' }
        : { title: 'Table of contents', show: 'Show table of contents', hide: 'Hide table of contents' };
      const tableWrappers = Array.from(document.querySelectorAll('.table-wrapper[data-enhanced-table]'));
      const tableLabels = CURRENT_LANG === 'it'
        ? { expand: 'Apri a schermo intero', close: 'Chiudi' }
        : { expand: 'Open full view', close: 'Close' };
      const codeBlocks = Array.from(document.querySelectorAll('.post-body pre'));
      const codeCopyLabels = {
        it: { copy: 'Copia', copied: 'Copiato!' },
        en: { copy: 'Copy', copied: 'Copied!' },
      };
      let tableOverlay = null;
      let tableOverlayScroll = null;
      let tableOverlayClose = null;
      if (tocTitle) {
        tocTitle.textContent = tocLabels.title;
      }
      if (tocToggleText) {
        tocToggleText.textContent = tocLabels.title;
      }
      let tocCollapsed = false;
      let tocManualOverride = false;
      const tocMediaQuery = window.matchMedia ? window.matchMedia('(max-width: 1024px)') : null;
      function ensureTableOverlay() {
        if (tableOverlay) {
          return;
        }
        tableOverlay = document.createElement('div');
        tableOverlay.className = 'table-overlay';
        tableOverlay.innerHTML =
          '<div class="table-overlay__content">' +
          '<button type="button" class="table-overlay__close">' + tableLabels.close + '</button>' +
          '<div class="table-overlay__scroll"></div>' +
          '</div>';
        body.appendChild(tableOverlay);
        tableOverlayScroll = tableOverlay.querySelector('.table-overlay__scroll');
        tableOverlayClose = tableOverlay.querySelector('.table-overlay__close');
        if (tableOverlayClose) {
          tableOverlayClose.setAttribute('aria-label', tableLabels.close);
          tableOverlayClose.addEventListener('click', closeTableOverlay);
        }
        tableOverlay.addEventListener('click', (event) => {
          if (event.target === tableOverlay) {
            closeTableOverlay();
          }
        });
      }
      function closeTableOverlay() {
        if (!tableOverlay) {
          return;
        }
        tableOverlay.classList.remove('table-overlay--visible');
        body.classList.remove('no-scroll');
        if (tableOverlayScroll) {
          tableOverlayScroll.innerHTML = '';
        }
      }
      function openTableOverlay(wrapper) {
        ensureTableOverlay();
        if (!tableOverlay || !tableOverlayScroll) {
          return;
        }
        tableOverlayScroll.innerHTML = '';
        const table = wrapper.querySelector('table');
        if (table) {
          const clone = table.cloneNode(true);
          const tableSize = table.dataset.tableSize;
          if (tableSize) {
            clone.dataset.tableSize = tableSize;
          }
          tableOverlayScroll.appendChild(clone);
        }
        tableOverlay.classList.add('table-overlay--visible');
        body.classList.add('no-scroll');
        if (tableOverlayClose) {
          tableOverlayClose.focus();
        }
      }
      function enhanceTables() {
        if (!tableWrappers.length) {
          return;
        }
        tableWrappers.forEach((wrapper) => {
          if (wrapper.dataset.enhanced === 'true') {
            return;
          }
          const table = wrapper.querySelector('table');
          if (!table) {
            return;
          }
          const headerCells = table.querySelectorAll('thead th');
          const referenceCells = headerCells.length ? headerCells : table.querySelectorAll('tr:first-child > *');
          const columnCount = referenceCells.length;
          let tableSize = '';
          if (columnCount >= 6) {
            tableSize = 'wide';
          } else if (columnCount >= 4) {
            tableSize = 'medium';
          }
          if (tableSize) {
            wrapper.setAttribute('data-table-size', tableSize);
            table.dataset.tableSize = tableSize;
          }
          const expandBtn = document.createElement('button');
          expandBtn.type = 'button';
          expandBtn.className = 'table-wrapper__expand';
          expandBtn.innerHTML = '<span aria-hidden="true">üîç</span> ' + tableLabels.expand;
          expandBtn.setAttribute('aria-label', tableLabels.expand);
          expandBtn.addEventListener('click', () => openTableOverlay(wrapper));
          wrapper.appendChild(expandBtn);
          wrapper.dataset.enhanced = 'true';
        });
      }
      function fallbackCopy(text) {
        const textarea = document.createElement('textarea');
        textarea.value = text;
        textarea.setAttribute('readonly', '');
        textarea.style.position = 'fixed';
        textarea.style.opacity = '0';
        textarea.style.left = '-9999px';
        document.body.appendChild(textarea);
        textarea.select();
        let successful = false;
        try {
          successful = document.execCommand('copy');
        } catch (error) {
          successful = false;
        }
        textarea.remove();
        return successful;
      }
      function showCopyFeedback(button, labels) {
        if (button._copyTimeout) {
          clearTimeout(button._copyTimeout);
        }
        const labelEl = button.querySelector('.code-copy-btn__text');
        button.classList.add('code-copy-btn--copied');
        if (labelEl) {
          labelEl.textContent = labels.copied;
        }
        button._copyTimeout = window.setTimeout(() => {
          button.classList.remove('code-copy-btn--copied');
          if (labelEl) {
            labelEl.textContent = labels.copy;
          }
        }, 2000);
      }
      function enhanceCodeBlocks() {
        if (!codeBlocks.length) {
          return;
        }
        const labels = codeCopyLabels[CURRENT_LANG] || codeCopyLabels.en;
        codeBlocks.forEach((pre) => {
          if (pre.dataset.copyEnhanced === 'true') {
            return;
          }
          const code = pre.querySelector('code');
          if (!code) {
            return;
          }
          const button = document.createElement('button');
          button.type = 'button';
          button.className = 'code-copy-btn';
          button.setAttribute('aria-label', labels.copy);
          button.innerHTML =
            '<span class="code-copy-btn__icon" aria-hidden="true">üìã</span>' +
            '<span class="code-copy-btn__text">' + labels.copy + '</span>';
          button.addEventListener('click', async () => {
            const text = (code.textContent || '').replace(/s+$/, '');
            if (!text) {
              return;
            }
            let copied = false;
            if (navigator.clipboard && typeof navigator.clipboard.writeText === 'function') {
              try {
                await navigator.clipboard.writeText(text);
                copied = true;
              } catch (error) {
                copied = false;
              }
            }
            if (!copied) {
              copied = fallbackCopy(text);
            }
            if (copied) {
              showCopyFeedback(button, labels);
            }
          });
          pre.appendChild(button);
          pre.dataset.copyEnhanced = 'true';
        });
      }
      function setTocCollapsed(collapsed, { manual = false } = {}) {
        if (!tocElement) {
          return;
        }
        tocCollapsed = Boolean(collapsed);
        if (manual) {
          tocManualOverride = true;
        }
        tocElement.classList.toggle('post-toc--collapsed', tocCollapsed);
        tocElement.setAttribute('data-collapsed', tocCollapsed ? 'true' : 'false');
        if (tocToggle) {
          tocToggle.setAttribute('aria-expanded', tocCollapsed ? 'false' : 'true');
          tocToggle.setAttribute('aria-label', tocCollapsed ? tocLabels.show : tocLabels.hide);
        }
      }
      function initToc() {
        if (!tocElement) {
          return;
        }
        if (tocToggle) {
          tocToggle.addEventListener('click', () => {
            setTocCollapsed(!tocCollapsed, { manual: true });
          });
        }
        if (tocMediaQuery) {
          const handleMediaChange = (event) => {
            if (tocManualOverride) {
              return;
            }
            setTocCollapsed(event.matches);
          };
          if (typeof tocMediaQuery.addEventListener === 'function') {
            tocMediaQuery.addEventListener('change', handleMediaChange);
          } else if (typeof tocMediaQuery.addListener === 'function') {
            tocMediaQuery.addListener(handleMediaChange);
          }
          setTocCollapsed(tocMediaQuery.matches);
        } else {
          setTocCollapsed(false);
        }
      }
      const storedTheme = (localStorage.getItem(BLOG_THEME_KEY) || '').toLowerCase();
      const prefersDark = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
      const initialTheme = storedTheme === 'light' ? 'light' : (storedTheme === 'dark' ? 'dark' : (prefersDark ? 'dark' : 'light'));
      let activeLink = null;
      let ticking = false;
      function applyTheme(theme) {
        const resolved = theme === 'dark' ? 'dark' : 'light';
        body.setAttribute('data-theme', resolved);
        if (themeToggle) {
          themeToggle.classList.toggle('active', resolved === 'dark');
        }
        if (themeThumb) {
          themeThumb.textContent = resolved === 'dark' ? 'üåô' : '‚òÄÔ∏è';
        }
        localStorage.setItem(BLOG_THEME_KEY, resolved);
      }
      function setActive(link) {
        if (activeLink === link) {
          return;
        }
        if (activeLink) {
          activeLink.classList.remove('post-toc__link--active');
        }
        if (link) {
          link.classList.add('post-toc__link--active');
        }
        activeLink = link;
      }
      function updateActiveHeading() {
        if (!headingEntries.length) {
          return;
        }
        const scrollPosition = window.scrollY + 160;
        let current = headingEntries[0];
        for (const item of headingEntries) {
          if (item.target.offsetTop <= scrollPosition) {
            current = item;
          } else {
            break;
          }
        }
        setActive(current.link);
      }
      function onScroll() {
        if (ticking) {
          return;
        }
        ticking = true;
        window.requestAnimationFrame(() => {
          updateActiveHeading();
          ticking = false;
        });
      }
      document.addEventListener('keydown', (event) => {
        if (event.key === 'Escape') {
          closeTableOverlay();
        }
      });
      enhanceTables();
      enhanceCodeBlocks();
      initToc();
      applyTheme(initialTheme);
      if (themeToggle) {
        themeToggle.addEventListener('click', () => {
          applyTheme(body.getAttribute('data-theme') === 'dark' ? 'light' : 'dark');
        });
      }
      if (langBtn) {
        langBtn.textContent = CURRENT_LANG === 'it' ? 'EN' : 'IT';
        if (OTHER_LANG_LINK) {
          langBtn.addEventListener('click', () => {
            localStorage.setItem(BLOG_LANG_KEY, OTHER_LANG);
            window.location.href = OTHER_LANG_LINK;
          });
        } else {
          langBtn.disabled = true;
          langBtn.classList.add('lang-btn--disabled');
        }
      }
      localStorage.setItem(BLOG_LANG_KEY, CURRENT_LANG);
      if (headingEntries.length) {
        headingEntries.sort((a, b) => a.target.offsetTop - b.target.offsetTop);
        updateActiveHeading();
        window.addEventListener('scroll', onScroll, { passive: true });
      }
    })();
  </script>
</body>
</html>